{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "23ca1766-070c-418e-afdf-4433cc90dbdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[INFO]\u001b[0m This is an info\n",
      "\u001b[31m[ERROR]\u001b[0m This is an error\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style\n",
    "\n",
    "def print_message(message_type, message):\n",
    "    if message_type == \"INFO\":\n",
    "        print(f\"{Fore.YELLOW}[INFO]{Style.RESET_ALL} {message}\")\n",
    "    elif message_type == \"ERROR\":\n",
    "        print(f\"{Fore.RED}[ERROR]{Style.RESET_ALL} {message}\")\n",
    "    elif message_type == \"SUCCESS\":\n",
    "        print(f\"{Fore.GREEN}[SUCESS]{Style.RESET_ALL} {message}\")\n",
    "    else:\n",
    "        print(f\"{message}\")\n",
    "\n",
    "print_message(\"INFO\", \"This is an info\")\n",
    "print_message(\"ERROR\", \"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5341e2-ee6b-4d2a-bcca-53a9b2fed3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae0e13a6-bed5-4292-b542-f4c377373be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_file_with_progress(url, output_path):\n",
    "   \n",
    "    response = requests.get(url, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        with open(output_path, 'wb') as file, tqdm(\n",
    "            desc=output_path,\n",
    "            total=total_size,\n",
    "            unit='B',\n",
    "            unit_scale=True,\n",
    "            unit_divisor=1024,\n",
    "        ) as progress_bar:\n",
    "            for chunk in response.iter_content(chunk_size=1024):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "                    progress_bar.update(len(chunk))\n",
    "        print_message(\"SUCCESS\", \"File has been successfully downloaded.\")\n",
    "    else:\n",
    "        print_message(\"ERROR\", f\"Something went wrong. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "090a7d4c-e3c2-45d3-93ce-9538d3d85c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_pdf_file(pdf_file_name: str) -> str:\n",
    "    if pdf_file_name[-4:] != \".pdf\":\n",
    "        pdf_file_name += \".pdf\"\n",
    "    if not os.path.exists(pdf_file_name):\n",
    "        print_message(\"INFO\", \"File doesn't exist, Insert Url here\")\n",
    "        url = input(\">\")\n",
    "\n",
    "        download_file_with_progress(url, pdf_file_name)\n",
    "    else:\n",
    "        print_message(\"SUCCESS\", \"The file already exists\")\n",
    "        return pdf_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9dc1ebb-e479-4156-a0c9-61d7d8a42a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[SUCESS]\u001b[0m The file already exists\n"
     ]
    }
   ],
   "source": [
    "pdf_file_name = \"Hands-On Machine Learning With - Aurelien Geron\"\n",
    "pdf_file_name = insert_pdf_file(pdf_file_name=pdf_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f8c63aaa-a416-4d07-a965-78271aa6532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def text_formatter(text: str) -> str:\n",
    "    cleaned_text = text.replace('\\n', ' ').strip()\n",
    "    return cleaned_text\n",
    "\n",
    "def open_and_read_pdf(pdf_file_name: str) -> list[dict]:\n",
    "    doc = fitz.open(pdf_file_name)\n",
    "    pages_and_texts = []\n",
    "    for page_number, page in tqdm(enumerate(doc)):\n",
    "        text = page.get_text()\n",
    "        text = text_formatter(text=text)\n",
    "        pages_and_texts.append({\n",
    "                \"page_number\": page_number + 1,\n",
    "                \"page_char_count\": len(text),\n",
    "                \"page_word_count\": len(text.split(' ')),\n",
    "                \"page_sentence_count_raw\": len(text.split(\". \")),\n",
    "                \"page_token_count\": len(text) / 4,\n",
    "                \"text\": text\n",
    "        })\n",
    "    return pages_and_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c54cc4d-aef6-46c1-b4b0-6f22d87adff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179f0d4a617d4d92914d4bb78fde99aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pages_and_texts = open_and_read_pdf(pdf_file_name=pdf_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69d9be4-7f7b-4323-8f45-3d697c3281f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_and_embed_pdf_file(pdf_file_name: str):\n",
    "    pdf_file_name = insert_pdf_file(pdf_file_name=pdf_file_name)\n",
    "    pages_and_texts = open_and_read_pdf(pdf_file_name_pdf_file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1b37a8c-e3e8-4659-8258-c86604fa9c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 689,\n",
       "  'page_char_count': 1562,\n",
       "  'page_word_count': 166,\n",
       "  'page_sentence_count_raw': 4,\n",
       "  'page_token_count': 390.5,\n",
       "  'text': 'Interleaving Lines from Multiple FilesFirst, suppose you’ve loaded the California housing dataset, shuffled it(unless it was already shuffled), and split it into a training set, a validationset, and a test set. Then you split each set into many CSV files that each looklike this (each row contains eight input features plus the target median housevalue):MedInc,HouseAge,AveRooms,AveBedrms,Popul…,AveOccup,Lat…,Long…,MedianHouseValue3.5214,15.0,3.050,1.107,1447.0,1.606,37.63,-122.43,1.4425.3275,5.0,6.490,0.991,3464.0,3.443,33.69,-117.39,1.6873.1,29.0,7.542,1.592,1328.0,2.251,38.44,-122.98,1.621[...]Let’s also suppose train_filepaths contains the list of training filepaths (andyou also have valid_filepaths and test_filepaths):>>> train_filepaths[\\'datasets/housing/my_train_00.csv\\', \\'datasets/housing/my_train_01.csv\\', ...]Alternatively, you could use file patterns; for example, train_filepaths =\"datasets/housing/my_train_*.csv\". Now let’s create a dataset containing onlythese filepaths:filepath_dataset = tf.data.Dataset.list_files(train_filepaths, seed=42)By default, the list_files() function returns a dataset that shuffles the filepaths.In general this is a good thing, but you can set shuffle=False if you do notwant that for some reason.Next, you can call the interleave() method to read from five files at a time andinterleave their lines. You can also skip the first line of each file—which isthe header row—using the skip() method):n_readers = 5dataset = filepath_dataset.interleave(    lambda filepath: tf.data.TextLineDataset(filepath).skip(1),'},\n",
       " {'page_number': 87,\n",
       "  'page_char_count': 1195,\n",
       "  'page_word_count': 197,\n",
       "  'page_sentence_count_raw': 5,\n",
       "  'page_token_count': 298.75,\n",
       "  'text': 'Select a Performance MeasureYour next step is to select a performance measure. A typical performancemeasure for regression problems is the root mean square error (RMSE). Itgives an idea of how much error the system typically makes in its predictions,with a higher weight given to large errors. Equation 2-1 shows themathematical formula to compute the RMSE.Equation 2-1. Root mean square error (RMSE)RMSE ( X , h ) = 1 m ∑ i=1 m h(x (i) )-y (i) 2NOTATIONSThis equation introduces several very common machine learningnotations that I will use throughout this book:m is the number of instances in the dataset you are measuring theRMSE on.For example, if you are evaluating the RMSE on a validationset of 2,000 districts, then m = 2,000.x  is a vector of all the feature values (excluding the label) of the iinstance in the dataset, and y  is its label (the desired output valuefor that instance).For example, if the first district in the dataset is located atlongitude –118.29°, latitude 33.91°, and it has 1,416 inhabitantswith a median income of $38,372, and the median house valueis $156,400 (ignoring other features for now), then:x (1) = - 118.29 33.91 1,416 38,372and:y (1) = 156,400(i)th(i)'},\n",
       " {'page_number': 193,\n",
       "  'page_char_count': 1678,\n",
       "  'page_word_count': 223,\n",
       "  'page_sentence_count_raw': 4,\n",
       "  'page_token_count': 419.5,\n",
       "  'text': '>>> y_scores = sgd_clf.decision_function([some_digit])>>> y_scoresarray([2164.22030239])>>> threshold = 0>>> y_some_digit_pred = (y_scores > threshold)array([ True])The SGDClassifier uses a threshold equal to 0, so the preceding code returnsthe same result as the predict() method (i.e., True). Let’s raise the threshold:>>> threshold = 3000>>> y_some_digit_pred = (y_scores > threshold)>>> y_some_digit_predarray([False])This confirms that raising the threshold decreases recall. The image actuallyrepresents a 5, and the classifier detects it when the threshold is 0, but itmisses it when the threshold is increased to 3,000.How do you decide which threshold to use? First, use the cross_val_predict()function to get the scores of all instances in the training set, but this timespecify that you want to return decision scores instead of predictions:y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3,                             method=\"decision_function\")With these scores, use the precision_recall_curve() function to computeprecision and recall for all possible thresholds (the function adds a lastprecision of 0 and a last recall of 1, corresponding to an infinite threshold):from sklearn.metrics import precision_recall_curveprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)Finally, use Matplotlib to plot precision and recall as functions of thethreshold value (Figure 3-5). Let’s show the threshold of 3,000 we selected:plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\", linewidth=2)plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\", linewidth=2)plt.vlines(threshold, 0, 1.0, \"k\", \"dotted\", label=\"threshold\")'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "random.sample(pages_and_texts, k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f75b54-24ae-48c7-b962-a3fa4797e3b5",
   "metadata": {},
   "source": [
    "## Get some more info on the data of the book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "261e4054-f538-46e4-85b4-717c8f643e1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>37.50</td>\n",
       "      <td>Hands-On Machine Learning withScikit-Learn, Ke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>869</td>\n",
       "      <td>93</td>\n",
       "      <td>4</td>\n",
       "      <td>217.25</td>\n",
       "      <td>Hands-On Machine Learning with Scikit-Learn, K...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6.75</td>\n",
       "      <td>October 2022: Third Edition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1150</td>\n",
       "      <td>157</td>\n",
       "      <td>5</td>\n",
       "      <td>287.50</td>\n",
       "      <td>Revision History for the Third Edition2022-10-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "0            1                0                1                        1   \n",
       "1            2              150               14                        1   \n",
       "2            3              869               93                        4   \n",
       "3            4               27                4                        1   \n",
       "4            5             1150              157                        5   \n",
       "\n",
       "   page_token_count                                               text  \n",
       "0              0.00                                                     \n",
       "1             37.50  Hands-On Machine Learning withScikit-Learn, Ke...  \n",
       "2            217.25  Hands-On Machine Learning with Scikit-Learn, K...  \n",
       "3              6.75                        October 2022: Third Edition  \n",
       "4            287.50  Revision History for the Third Edition2022-10-...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e7e4911-ad7f-4f99-9ec0-4e780e73ae21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>676.00</td>\n",
       "      <td>1284.83</td>\n",
       "      <td>192.12</td>\n",
       "      <td>6.09</td>\n",
       "      <td>321.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>390.14</td>\n",
       "      <td>584.26</td>\n",
       "      <td>96.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>146.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>338.50</td>\n",
       "      <td>909.50</td>\n",
       "      <td>115.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>227.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>676.00</td>\n",
       "      <td>1311.00</td>\n",
       "      <td>195.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>327.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1013.50</td>\n",
       "      <td>1749.50</td>\n",
       "      <td>267.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>437.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>3066.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>766.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1351.00          1351.00          1351.00                  1351.00   \n",
       "mean        676.00          1284.83           192.12                     6.09   \n",
       "std         390.14           584.26            96.68                     3.94   \n",
       "min           1.00             0.00             1.00                     1.00   \n",
       "25%         338.50           909.50           115.00                     3.00   \n",
       "50%         676.00          1311.00           195.00                     6.00   \n",
       "75%        1013.50          1749.50           267.00                     8.00   \n",
       "max        1351.00          3066.00           506.00                    33.00   \n",
       "\n",
       "       page_token_count  \n",
       "count           1351.00  \n",
       "mean             321.21  \n",
       "std              146.06  \n",
       "min                0.00  \n",
       "25%              227.38  \n",
       "50%              327.75  \n",
       "75%              437.38  \n",
       "max              766.50  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2f0843-ed98-4741-9b6b-ead4496a64d4",
   "metadata": {},
   "source": [
    "## Splitting pages into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb064551-ca85-4ee9-ac47-243386fd49c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[This is a sentence., This is another sentence., I like this.]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.lang.en import English\n",
    "\n",
    "nlp = English()\n",
    "\n",
    "nlp.add_pipe(\"sentencizer\")\n",
    "\n",
    "doc = nlp(\"This is a sentence. This is another sentence. I like this.\")\n",
    "assert len(list(doc.sents)) == 3\n",
    "\n",
    "list(doc.sents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5e26815d-81ca-4bb0-82f9-0f70bf9b6ee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7cabacf28b447094d860a32452642a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentences\"] = list(nlp(item['text']).sents)\n",
    "\n",
    "    item['sentences'] = [str(sentence) for sentence in item[\"sentences\"]]\n",
    "    item[\"page_sentence_count_spacy\"] = len(item[\"sentences\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a16afd77-3914-4458-839b-f990b6240541",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 910,\n",
       "  'page_char_count': 2051,\n",
       "  'page_word_count': 313,\n",
       "  'page_sentence_count_raw': 11,\n",
       "  'page_token_count': 512.75,\n",
       "  'text': 'MaskingMaking the model ignore padding tokens is trivial using Keras: simply addmask_zero=True when creating the Embedding layer. This means thatpadding tokens (whose ID is 0) will be ignored by all downstream layers.That’s all! If you retrain the previous model for a few epochs, you will findthat the validation accuracy quickly reaches over 80%.The way this works is that the Embedding layer creates a mask tensor equalto tf.math.not_equal(inputs, 0): it is a Boolean tensor with the same shape asthe inputs, and it is equal to False anywhere the token IDs are 0, or Trueotherwise. This mask tensor is then automatically propagated by the model tothe next layer. If that layer’s call() method has a mask argument, then itautomatically receives the mask. This allows the layer to ignore theappropriate time steps. Each layer may handle the mask differently, but ingeneral they simply ignore masked time steps (i.e., time steps for which themask is False). For example, when a recurrent layer encounters a maskedtime step, it simply copies the output from the previous time step.Next, if the layer’s supports_masking attribute is True, then the mask isautomatically propagated to the next layer. It keeps propagating this way foras long as the layers have supports_masking=True. As an example, arecurrent layer’s supports_mask\\u2060 ing attribute is True whenreturn_sequences=True, but it’s False when return_sequen\\u2060 ces=False sincethere’s no need for a mask anymore in this case. So if you have a model withseveral recurrent layers with return_sequences=True, followed by a recurrentlayer with return_sequences=False, then the mask will automaticallypropagate up to the last recurrent layer: that layer will use the mask to ignoremasked steps, but it will not propagate the mask any further. Similarly, if youset mask_zero=True when creating the Embedding layer in the sentimentanalysis model we just built, then the GRU layer will receive and use themask automatically, but it will not propagate it any further, sincereturn_sequences is not set to True.',\n",
       "  'sentences': ['MaskingMaking the model ignore padding tokens is trivial using Keras: simply addmask_zero=True when creating the Embedding layer.',\n",
       "   'This means thatpadding tokens (whose ID is 0) will be ignored by all downstream layers.',\n",
       "   'That’s all!',\n",
       "   'If you retrain the previous model for a few epochs, you will findthat the validation accuracy quickly reaches over 80%.The way this works is that the Embedding layer creates a mask tensor equalto tf.math.not_equal(inputs, 0): it is a Boolean tensor with the same shape asthe inputs, and it is equal to False anywhere the token IDs are 0, or Trueotherwise.',\n",
       "   'This mask tensor is then automatically propagated by the model tothe next layer.',\n",
       "   'If that layer’s call() method has a mask argument, then itautomatically receives the mask.',\n",
       "   'This allows the layer to ignore theappropriate time steps.',\n",
       "   'Each layer may handle the mask differently, but ingeneral they simply ignore masked time steps (i.e., time steps for which themask is False).',\n",
       "   'For example, when a recurrent layer encounters a maskedtime step, it simply copies the output from the previous time step.',\n",
       "   'Next, if the layer’s supports_masking attribute is True, then the mask isautomatically propagated to the next layer.',\n",
       "   'It keeps propagating this way foras long as the layers have supports_masking=True.',\n",
       "   'As an example, arecurrent layer’s supports_mask\\u2060 ing attribute is True whenreturn_sequences=True, but it’s False when return_sequen\\u2060 ces=False sincethere’s no need for a mask anymore in this case.',\n",
       "   'So if you have a model withseveral recurrent layers with return_sequences=True, followed by a recurrentlayer with return_sequences=False, then the mask will automaticallypropagate up to the last recurrent layer: that layer will use the mask to ignoremasked steps, but it will not propagate the mask any further.',\n",
       "   'Similarly, if youset mask_zero=True when creating the Embedding layer in the sentimentanalysis model we just built, then the GRU layer will receive and use themask automatically, but it will not propagate it any further, sincereturn_sequences is not set to True.'],\n",
       "  'page_sentence_count_spacy': 14}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2dd2c36d-ad80-4440-8af6-903ca30b5bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1351.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1351.0</td>\n",
       "      <td>1351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>676.0</td>\n",
       "      <td>1285.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>390.0</td>\n",
       "      <td>584.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>338.0</td>\n",
       "      <td>910.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>227.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>676.0</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>328.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1014.0</td>\n",
       "      <td>1750.0</td>\n",
       "      <td>267.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>437.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1351.0</td>\n",
       "      <td>3066.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>766.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count       1351.0           1351.0           1351.0                   1351.0   \n",
       "mean         676.0           1285.0            192.0                      6.0   \n",
       "std          390.0            584.0             97.0                      4.0   \n",
       "min            1.0              0.0              1.0                      1.0   \n",
       "25%          338.0            910.0            115.0                      3.0   \n",
       "50%          676.0           1311.0            195.0                      6.0   \n",
       "75%         1014.0           1750.0            267.0                      8.0   \n",
       "max         1351.0           3066.0            506.0                     33.0   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  \n",
       "count            1351.0                     1351.0  \n",
       "mean              321.0                        9.0  \n",
       "std               146.0                        6.0  \n",
       "min                 0.0                        0.0  \n",
       "25%               227.0                        4.0  \n",
       "50%               328.0                        8.0  \n",
       "75%               437.0                       12.0  \n",
       "max               766.0                       52.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feec6e04-402c-4a0e-ab8c-b2110ff6ef9a",
   "metadata": {},
   "source": [
    "### Making chunks from the text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "88c55355-dbdd-4d20-8411-9ed50ac48812",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sentence_chunk_size = 10 \n",
    "\n",
    "def split_list(input_list: list, slice_size: int =num_sentence_chunk_size) -> list[str]:\n",
    "    return [input_list[i:i+slice_size + 1] for i in range(0, len(input_list), slice_size)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "969e20aa-3916-426e-ba25-576bcb90b9ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " [10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
       " [20, 21, 22, 23, 24]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tl = list(range(25))\n",
    "split_list(tl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4ad95769-5bef-4ee4-a7a5-6bd3db3b00eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4d979cf7534315a9bfc7851b837511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for item in tqdm(pages_and_texts):\n",
    "    item[\"sentence_chunks\"] = split_list(input_list=item[\"sentences\"],\n",
    "                                        slice_size=num_sentence_chunk_size)\n",
    "    item[\"num_chunks\"] = len(item[\"sentence_chunks\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1c80c586-d3a6-4b67-833a-52fba584fc9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 1007,\n",
       "  'page_char_count': 1828,\n",
       "  'page_word_count': 250,\n",
       "  'page_sentence_count_raw': 7,\n",
       "  'page_token_count': 457.0,\n",
       "  'text': 'Let’s start building a variational autoencoder for Fashion MNIST (as shownin Figure 17-11, but using the γ tweak). First, we will need a custom layer tosample the codings, given μ and γ:class Sampling(tf.keras.layers.Layer):    def call(self, inputs):        mean, log_var = inputs        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + meanThis Sampling layer takes two inputs: mean (μ) and log_var (γ). It uses thefunction tf.random.normal() to sample a random vector (of the same shape asγ) from the Gaussian distribution, with mean 0 and standard deviation 1.Then it multiplies it by exp(γ / 2) (which is equal to σ, as you can verifymathematically), and finally it adds μ and returns the result. This samples acodings vector from the Gaussian distribution with mean μ and standarddeviation σ.Next, we can create the encoder, using the functional API because the modelis not entirely sequential:codings_size = 10inputs = tf.keras.layers.Input(shape=[28, 28])Z = tf.keras.layers.Flatten()(inputs)Z = tf.keras.layers.Dense(150, activation=\"relu\")(Z)Z = tf.keras.layers.Dense(100, activation=\"relu\")(Z)codings_mean = tf.keras.layers.Dense(codings_size)(Z)  # μcodings_log_var = tf.keras.layers.Dense(codings_size)(Z)  # γcodings = Sampling()([codings_mean, codings_log_var])variational_encoder = tf.keras.Model(    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])Note that the Dense layers that output codings_mean (μ) andcodings_log_var (γ) have the same inputs (i.e., the outputs of the secondDense layer). We then pass both codings_mean and codings_log_var to theSampling layer. Finally, the variational_encoder model has three outputs.Only the codings are required, but we add codings_mean andcodings_log_var as well, in case we want to inspect their values. Now let’sbuild the decoder:',\n",
       "  'sentences': ['Let’s start building a variational autoencoder for Fashion MNIST (as shownin Figure 17-11, but using the γ tweak).',\n",
       "   'First, we will need a custom layer tosample the codings, given μ and γ:class Sampling(tf.keras.layers.',\n",
       "   'Layer):    def call(self, inputs):        mean, log_var = inputs        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + meanThis Sampling layer takes two inputs: mean (μ) and log_var (γ).',\n",
       "   'It uses thefunction tf.random.normal() to sample a random vector (of the same shape asγ) from the Gaussian distribution, with mean 0 and standard deviation 1.Then it multiplies it by exp(γ / 2) (which is equal to σ, as you can verifymathematically), and finally it adds μ and returns the result.',\n",
       "   'This samples acodings vector from the Gaussian distribution with mean μ and standarddeviation σ.',\n",
       "   'Next, we can create the encoder, using the functional API because the modelis not entirely sequential:codings_size = 10inputs = tf.keras.layers.',\n",
       "   'Input(shape=[28, 28])Z = tf.keras.layers.',\n",
       "   'Flatten()(inputs)Z = tf.keras.layers.',\n",
       "   'Dense(150, activation=\"relu\")(Z)Z = tf.keras.layers.',\n",
       "   'Dense(100, activation=\"relu\")(Z)codings_mean = tf.keras.layers.',\n",
       "   'Dense(codings_size)(Z)  # μcodings_log_var = tf.keras.layers.',\n",
       "   'Dense(codings_size)(Z)  # γcodings = Sampling()([codings_mean, codings_log_var])variational_encoder = tf.keras.',\n",
       "   'Model(    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])Note that the Dense layers that output codings_mean (μ) andcodings_log_var (γ) have the same inputs (i.e., the outputs of the secondDense layer).',\n",
       "   'We then pass both codings_mean and codings_log_var to theSampling layer.',\n",
       "   'Finally, the variational_encoder model has three outputs.',\n",
       "   'Only the codings are required, but we add codings_mean andcodings_log_var as well, in case we want to inspect their values.',\n",
       "   'Now let’sbuild the decoder:'],\n",
       "  'page_sentence_count_spacy': 17,\n",
       "  'sentence_chunks': [['Let’s start building a variational autoencoder for Fashion MNIST (as shownin Figure 17-11, but using the γ tweak).',\n",
       "    'First, we will need a custom layer tosample the codings, given μ and γ:class Sampling(tf.keras.layers.',\n",
       "    'Layer):    def call(self, inputs):        mean, log_var = inputs        return tf.random.normal(tf.shape(log_var)) * tf.exp(log_var / 2) + meanThis Sampling layer takes two inputs: mean (μ) and log_var (γ).',\n",
       "    'It uses thefunction tf.random.normal() to sample a random vector (of the same shape asγ) from the Gaussian distribution, with mean 0 and standard deviation 1.Then it multiplies it by exp(γ / 2) (which is equal to σ, as you can verifymathematically), and finally it adds μ and returns the result.',\n",
       "    'This samples acodings vector from the Gaussian distribution with mean μ and standarddeviation σ.',\n",
       "    'Next, we can create the encoder, using the functional API because the modelis not entirely sequential:codings_size = 10inputs = tf.keras.layers.',\n",
       "    'Input(shape=[28, 28])Z = tf.keras.layers.',\n",
       "    'Flatten()(inputs)Z = tf.keras.layers.',\n",
       "    'Dense(150, activation=\"relu\")(Z)Z = tf.keras.layers.',\n",
       "    'Dense(100, activation=\"relu\")(Z)codings_mean = tf.keras.layers.',\n",
       "    'Dense(codings_size)(Z)  # μcodings_log_var = tf.keras.layers.'],\n",
       "   ['Dense(codings_size)(Z)  # μcodings_log_var = tf.keras.layers.',\n",
       "    'Dense(codings_size)(Z)  # γcodings = Sampling()([codings_mean, codings_log_var])variational_encoder = tf.keras.',\n",
       "    'Model(    inputs=[inputs], outputs=[codings_mean, codings_log_var, codings])Note that the Dense layers that output codings_mean (μ) andcodings_log_var (γ) have the same inputs (i.e., the outputs of the secondDense layer).',\n",
       "    'We then pass both codings_mean and codings_log_var to theSampling layer.',\n",
       "    'Finally, the variational_encoder model has three outputs.',\n",
       "    'Only the codings are required, but we add codings_mean andcodings_log_var as well, in case we want to inspect their values.',\n",
       "    'Now let’sbuild the decoder:']],\n",
       "  'num_chunks': 2},\n",
       " {'page_number': 1062,\n",
       "  'page_char_count': 1600,\n",
       "  'page_word_count': 239,\n",
       "  'page_sentence_count_raw': 7,\n",
       "  'page_token_count': 400.0,\n",
       "  'text': 'reward_mean = flat_rewards.mean()    reward_std = flat_rewards.std()    return [(discounted_rewards - reward_mean) / reward_std            for discounted_rewards in all_discounted_rewards]Let’s check that this works:>>> discount_rewards([10, 0, -50], discount_factor=0.8)array([-22, -40, -50])>>> discount_and_normalize_rewards([[10, 0, -50], [10, 20]],...                                discount_factor=0.8)...[array([-0.28435071, -0.86597718, -1.18910299]), array([1.26665318, 1.0727777 ])]The call to discount_rewards() returns exactly what we expect (see Figure 18-6). You can verify that the function discount_and_normalize_rewards() doesindeed return the normalized action advantages for each action in bothepisodes. Notice that the first episode was much worse than the second, so itsnormalized advantages are all negative; all actions from the first episodewould be considered bad, and conversely all actions from the second episodewould be considered good.We are almost ready to run the algorithm! Now let’s define thehyperparameters. We will run 150 training iterations, playing 10 episodes periteration, and each episode will last at most 200 steps. We will use a discountfactor of 0.95:n_iterations = 150n_episodes_per_update = 10n_max_steps = 200discount_factor = 0.95We also need an optimizer and the loss function. A regular Nadam optimizerwith learning rate 0.01 will do just fine, and we will use the binary cross-entropy loss function because we are training a binary classifier (there aretwo possible actions—left or right):optimizer = tf.keras.optimizers.Nadam(learning_rate=0.01)',\n",
       "  'sentences': ['reward_mean = flat_rewards.mean()    reward_std = flat_rewards.std()    return [(discounted_rewards - reward_mean) / reward_std            for discounted_rewards in all_discounted_rewards]Let’s check that this works:>>> discount_rewards([10, 0, -50], discount_factor=0.8)array([-22, -40, -50])>>> discount_and_normalize_rewards([[10, 0, -50], [10, 20]],...                                discount_factor=0.8)...[array([-0.28435071, -0.86597718, -1.18910299]), array([1.26665318, 1.0727777 ])]The call to discount_rewards() returns exactly what we expect (see Figure 18-6).',\n",
       "   'You can verify that the function discount_and_normalize_rewards() doesindeed return the normalized action advantages for each action in bothepisodes.',\n",
       "   'Notice that the first episode was much worse than the second, so itsnormalized advantages are all negative; all actions from the first episodewould be considered bad, and conversely all actions from the second episodewould be considered good.',\n",
       "   'We are almost ready to run the algorithm!',\n",
       "   'Now let’s define thehyperparameters.',\n",
       "   'We will run 150 training iterations, playing 10 episodes periteration, and each episode will last at most 200 steps.',\n",
       "   'We will use a discountfactor of 0.95:n_iterations = 150n_episodes_per_update = 10n_max_steps = 200discount_factor = 0.95We also need an optimizer and the loss function.',\n",
       "   'A regular Nadam optimizerwith learning rate 0.01 will do just fine, and we will use the binary cross-entropy loss function because we are training a binary classifier (there aretwo possible actions—left or right):optimizer = tf.keras.optimizers.',\n",
       "   'Nadam(learning_rate=0.01)'],\n",
       "  'page_sentence_count_spacy': 9,\n",
       "  'sentence_chunks': [['reward_mean = flat_rewards.mean()    reward_std = flat_rewards.std()    return [(discounted_rewards - reward_mean) / reward_std            for discounted_rewards in all_discounted_rewards]Let’s check that this works:>>> discount_rewards([10, 0, -50], discount_factor=0.8)array([-22, -40, -50])>>> discount_and_normalize_rewards([[10, 0, -50], [10, 20]],...                                discount_factor=0.8)...[array([-0.28435071, -0.86597718, -1.18910299]), array([1.26665318, 1.0727777 ])]The call to discount_rewards() returns exactly what we expect (see Figure 18-6).',\n",
       "    'You can verify that the function discount_and_normalize_rewards() doesindeed return the normalized action advantages for each action in bothepisodes.',\n",
       "    'Notice that the first episode was much worse than the second, so itsnormalized advantages are all negative; all actions from the first episodewould be considered bad, and conversely all actions from the second episodewould be considered good.',\n",
       "    'We are almost ready to run the algorithm!',\n",
       "    'Now let’s define thehyperparameters.',\n",
       "    'We will run 150 training iterations, playing 10 episodes periteration, and each episode will last at most 200 steps.',\n",
       "    'We will use a discountfactor of 0.95:n_iterations = 150n_episodes_per_update = 10n_max_steps = 200discount_factor = 0.95We also need an optimizer and the loss function.',\n",
       "    'A regular Nadam optimizerwith learning rate 0.01 will do just fine, and we will use the binary cross-entropy loss function because we are training a binary classifier (there aretwo possible actions—left or right):optimizer = tf.keras.optimizers.',\n",
       "    'Nadam(learning_rate=0.01)']],\n",
       "  'num_chunks': 1}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_texts, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2b83eea-fdd9-43be-8097-37e8a6c6ef5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>page_char_count</th>\n",
       "      <th>page_word_count</th>\n",
       "      <th>page_sentence_count_raw</th>\n",
       "      <th>page_token_count</th>\n",
       "      <th>page_sentence_count_spacy</th>\n",
       "      <th>num_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "      <td>1351.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>676.00</td>\n",
       "      <td>1284.83</td>\n",
       "      <td>192.12</td>\n",
       "      <td>6.09</td>\n",
       "      <td>321.21</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>390.14</td>\n",
       "      <td>584.26</td>\n",
       "      <td>96.68</td>\n",
       "      <td>3.94</td>\n",
       "      <td>146.06</td>\n",
       "      <td>5.71</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>338.50</td>\n",
       "      <td>909.50</td>\n",
       "      <td>115.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>227.38</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>676.00</td>\n",
       "      <td>1311.00</td>\n",
       "      <td>195.00</td>\n",
       "      <td>6.00</td>\n",
       "      <td>327.75</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1013.50</td>\n",
       "      <td>1749.50</td>\n",
       "      <td>267.00</td>\n",
       "      <td>8.00</td>\n",
       "      <td>437.38</td>\n",
       "      <td>12.00</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>3066.00</td>\n",
       "      <td>506.00</td>\n",
       "      <td>33.00</td>\n",
       "      <td>766.50</td>\n",
       "      <td>52.00</td>\n",
       "      <td>6.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  page_char_count  page_word_count  page_sentence_count_raw  \\\n",
       "count      1351.00          1351.00          1351.00                  1351.00   \n",
       "mean        676.00          1284.83           192.12                     6.09   \n",
       "std         390.14           584.26            96.68                     3.94   \n",
       "min           1.00             0.00             1.00                     1.00   \n",
       "25%         338.50           909.50           115.00                     3.00   \n",
       "50%         676.00          1311.00           195.00                     6.00   \n",
       "75%        1013.50          1749.50           267.00                     8.00   \n",
       "max        1351.00          3066.00           506.00                    33.00   \n",
       "\n",
       "       page_token_count  page_sentence_count_spacy  num_chunks  \n",
       "count           1351.00                    1351.00     1351.00  \n",
       "mean             321.21                       8.68        1.38  \n",
       "std              146.06                       5.71        0.58  \n",
       "min                0.00                       0.00        0.00  \n",
       "25%              227.38                       4.00        1.00  \n",
       "50%              327.75                       8.00        1.00  \n",
       "75%              437.38                      12.00        2.00  \n",
       "max              766.50                      52.00        6.00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_texts)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ea8023c3-4672-4b38-914b-c8ca2d061d88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e18211018aa40a6b1d35e8249663066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1351 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1860"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pages_and_chunks = []\n",
    "for i in tqdm(pages_and_texts):\n",
    "    for sentence_chunk in i['sentence_chunks']:\n",
    "        chunk_dict = {}\n",
    "        chunk_dict[\"page_number\"] = i[\"page_number\"]\n",
    "        joined_sentence_chunk = \"\".join(sentence_chunk).replace(\"  \", \" \").strip()\n",
    "        joined_sentence_chunk = re.sub(r'\\.([A-Z])', r'. \\1', joined_sentence_chunk)\n",
    "        chunk_dict[\"sentence_chunk\"] = joined_sentence_chunk\n",
    "        chunk_dict[\"chunk_char_count\"] = len(joined_sentence_chunk)\n",
    "        chunk_dict[\"chunk_word_count\"] = len([word for word in joined_sentence_chunk.split(\" \")])\n",
    "        chunk_dict[\"chunk_token_count\"] = len(joined_sentence_chunk) / 4\n",
    "        pages_and_chunks.append(chunk_dict)\n",
    "    \n",
    "len(pages_and_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "641a8851-07aa-46f8-897e-2d263229f77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 267,\n",
       "  'sentence_chunk': \"With stochastic and mini-batch gradient descent, the curves are not so smooth, and it maybe hard to know whether you have reached the minimum or not. One solution is to stoponly after the validation error has been above the minimum for some time (when you areconfident that the model will not do any better), then roll back the model parameters to thepoint where the validation error was at a minimum. Here is a basic implementation of early stopping:from copy import deepcopyfrom sklearn.metrics import mean_squared_errorfrom sklearn.preprocessing import StandardScalerX_train, y_train, X_valid, y_valid = [...] # split the quadratic datasetpreprocessing = make_pipeline(PolynomialFeatures(degree=90, include_bias=False),               StandardScaler())X_train_prep = preprocessing.fit_transform(X_train)X_valid_prep = preprocessing.transform(X_valid)sgd_reg = SGDRegressor(penalty=None, eta0=0.002, random_state=42)n_epochs = 500best_valid_rmse = float('inf')for epoch in range(n_epochs):  sgd_reg.partial_fit(X_train_prep, y_train)  y_valid_predict = sgd_reg.predict(X_valid_prep)  val_error = mean_squared_error(y_valid, y_valid_predict, squared=False)  if val_error < best_valid_rmse:    best_valid_rmse = val_error    best_model = deepcopy(sgd_reg)This code first adds the polynomial features and scales all the input features,both for the training set and for the validation set (the code assumes that youhave split the original training set into a smaller training set and a validationset). Then it creates an SGDRegressor model with no regularization and asmall learning rate. In the training loop, it calls partial_fit() instead of fit(), toperform incremental learning. At each epoch, it measures the RMSE on thevalidation set. If it is lower than the lowest RMSE seen so far, it saves a copyof the model in the best_model variable. This implementation does notactually stop training, but it lets you revert to the best model after training. Note that the model is copied using copy.deepcopy(), because it copies both\",\n",
       "  'chunk_char_count': 2028,\n",
       "  'chunk_word_count': 285,\n",
       "  'chunk_token_count': 507.0},\n",
       " {'page_number': 1120,\n",
       "  'sentence_chunk': 'For this we will use the google-cloud-storage library, which is preinstalled in Colab. We first create a Clientobject, which will serve as the interface with GCS, then we use it to createthe bucket:from google.cloud import storage',\n",
       "  'chunk_char_count': 230,\n",
       "  'chunk_word_count': 36,\n",
       "  'chunk_token_count': 57.5}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks, k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ce5516c-c898-42ad-916f-efd7cef1fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1860.00</td>\n",
       "      <td>1860.00</td>\n",
       "      <td>1860.00</td>\n",
       "      <td>1860.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>676.23</td>\n",
       "      <td>962.78</td>\n",
       "      <td>141.11</td>\n",
       "      <td>240.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>376.24</td>\n",
       "      <td>562.09</td>\n",
       "      <td>85.76</td>\n",
       "      <td>140.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>360.75</td>\n",
       "      <td>492.75</td>\n",
       "      <td>73.00</td>\n",
       "      <td>123.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>680.00</td>\n",
       "      <td>995.50</td>\n",
       "      <td>131.00</td>\n",
       "      <td>248.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>996.00</td>\n",
       "      <td>1411.00</td>\n",
       "      <td>210.00</td>\n",
       "      <td>352.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1351.00</td>\n",
       "      <td>3052.00</td>\n",
       "      <td>492.00</td>\n",
       "      <td>763.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       page_number  chunk_char_count  chunk_word_count  chunk_token_count\n",
       "count      1860.00           1860.00           1860.00            1860.00\n",
       "mean        676.23            962.78            141.11             240.70\n",
       "std         376.24            562.09             85.76             140.52\n",
       "min           2.00              3.00              1.00               0.75\n",
       "25%         360.75            492.75             73.00             123.19\n",
       "50%         680.00            995.50            131.00             248.88\n",
       "75%         996.00           1411.00            210.00             352.75\n",
       "max        1351.00           3052.00            492.00             763.00"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(pages_and_chunks)\n",
    "df.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e002c64-19e5-467d-ada7-48623eae3a7b",
   "metadata": {},
   "source": [
    "## Filter out chunks with less than 20 tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c435930a-fd6e-4ec9-82d4-f1e2d87b25da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk token count: 19.25 | Text: Figure 19-6. Executing a TensorFlow graph across multiple devices in parallel\n",
      "Chunk token count: 11.0 | Text: the data. For now, let’s go with this model.\n",
      "Chunk token count: 6.5 | Text: How muchdoes PCA help now?\n",
      "Chunk token count: 19.25 | Text: Now let’s look at the second common building block of CNNs: the poolinglayer.\n",
      "Chunk token count: 14.75 | Text: Tensor: shape=(2, 3), dtype=int64, numpy= array([[0, 1, 2],\n"
     ]
    }
   ],
   "source": [
    "min_token_lenght = 20\n",
    "for row in df[df[\"chunk_token_count\"] <= min_token_lenght].sample(5).iterrows():\n",
    "    print(f\"Chunk token count: {row[1]['chunk_token_count']} | Text: {row[1]['sentence_chunk']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d930fabe-7c87-446f-9f2e-a286bfedf846",
   "metadata": {},
   "outputs": [],
   "source": [
    "pages_and_chunks_over_min_token_len = df[df[\"chunk_token_count\"] > min_token_lenght].to_dict(orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7e6deb7e-bfd3-4bdb-bf60-c23b1cb7e06f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'page_number': 937,\n",
       "  'sentence_chunk': 'Figure 16-8. The original 2017 transformer architecture\\u2060If you use the transformer for NMT, then during training you must feed the22',\n",
       "  'chunk_char_count': 132,\n",
       "  'chunk_word_count': 20,\n",
       "  'chunk_token_count': 33.0}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(pages_and_chunks_over_min_token_len, k=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5134c9c8-dc3f-442d-9209-d2b7229887f7",
   "metadata": {},
   "source": [
    "## Embedding chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8dedbf60-4e9b-4296-a6d4-58c8b9a2b512",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\"Hello This is a test for the embedding model\",\n",
    "                 \"this is a second sentence for the model\",\n",
    "                 \"The sky is blue\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e9359d1-4266-4602-93bc-53b576e72ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\",\n",
    "                                     device=\"cuda\")\n",
    "\n",
    "\n",
    "embeddings = embedding_model.encode(test_sentences,\n",
    "                                    batch_size=32,\n",
    "                                    convert_to_tensor=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4bbdd38-56cd-4327-b98f-ea3f96b6ef0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_and_embeddings = dict(zip(test_sentences, embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6eb9ddc-efee-48f1-b0d6-bc1e46aae203",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Hello This is a test for the embedding model': tensor([-5.1741e-04, -8.9576e-02, -4.3483e-02,  6.3491e-02, -1.5166e-02,\n",
       "          3.6753e-02,  5.0416e-02,  2.7074e-02,  4.1897e-02,  1.8115e-03,\n",
       "          6.2513e-02, -9.2316e-03,  2.6844e-03,  5.2567e-02,  3.8520e-02,\n",
       "         -4.6451e-02,  5.5088e-02,  2.7253e-02, -9.0316e-03, -1.0031e-02,\n",
       "         -1.9533e-02, -5.2470e-02,  4.5585e-03,  1.2949e-02, -1.9578e-02,\n",
       "          2.3228e-02, -2.3299e-02,  5.9363e-03, -7.0727e-03, -5.1463e-02,\n",
       "         -1.7793e-02,  2.3849e-02,  5.1635e-02, -3.2830e-02,  1.4976e-06,\n",
       "         -5.8171e-02, -1.4653e-02,  6.8788e-03, -8.3841e-03,  1.3590e-02,\n",
       "          1.0240e-02,  6.2663e-02, -7.4270e-03,  2.7005e-02, -2.4735e-02,\n",
       "         -1.4349e-02, -1.6881e-02,  4.8620e-02, -1.3179e-02,  5.7703e-02,\n",
       "          6.5349e-03,  2.2798e-03, -2.4195e-02, -3.1098e-02,  5.1947e-02,\n",
       "          2.4326e-02,  3.8770e-02,  3.3131e-02, -6.9657e-03,  3.5400e-02,\n",
       "         -3.7303e-02,  1.6646e-02,  2.4014e-02,  3.6676e-02,  4.7199e-02,\n",
       "          2.9369e-02,  8.6796e-02, -2.9985e-02,  4.0537e-02,  5.5708e-03,\n",
       "          6.5119e-02,  1.4509e-02,  2.8657e-02,  8.9481e-02,  2.2189e-02,\n",
       "          6.7296e-02,  4.3063e-03, -3.0754e-02,  3.1389e-02, -9.7649e-03,\n",
       "         -8.8222e-03,  5.0234e-02,  1.1227e-02, -4.7887e-02, -1.6789e-02,\n",
       "         -2.3837e-04,  1.3134e-02, -3.0588e-02, -4.6851e-02, -1.1730e-02,\n",
       "         -1.3734e-02, -2.6956e-02, -1.4703e-03, -2.5719e-02,  1.2039e-02,\n",
       "         -3.3601e-02, -2.1750e-02, -6.5095e-03,  4.1026e-02, -3.5098e-02,\n",
       "          5.8729e-02, -7.7976e-03,  1.1163e-02,  5.6933e-02, -3.0623e-02,\n",
       "          4.7454e-02, -1.1121e-02,  3.8515e-02, -2.6151e-02,  9.1868e-02,\n",
       "         -6.2359e-02,  3.3298e-03, -1.9150e-02,  3.0149e-02,  4.6603e-02,\n",
       "         -5.5430e-02, -1.2846e-02,  1.7783e-02, -1.7369e-02,  6.0084e-02,\n",
       "         -4.0347e-02, -4.7456e-04,  2.9225e-02,  7.8668e-02, -3.0583e-02,\n",
       "         -3.5824e-02, -4.5679e-02, -2.7486e-02,  8.7179e-03,  2.5145e-02,\n",
       "         -4.1498e-03,  3.7924e-03,  1.0247e-02, -2.7623e-02, -4.6076e-03,\n",
       "          4.8509e-02,  4.7061e-02, -3.1982e-02, -2.6586e-02, -1.1234e-02,\n",
       "          3.0660e-02, -2.5561e-02,  2.7919e-02, -3.2622e-02, -1.3833e-02,\n",
       "          1.6839e-02,  1.0267e-02,  3.7019e-03, -1.0300e-02, -1.3312e-02,\n",
       "         -4.3982e-02,  5.6308e-02,  4.1751e-02, -2.2242e-02,  4.8350e-02,\n",
       "          1.1824e-02,  6.1103e-02,  5.7214e-02, -2.1682e-02, -2.1462e-02,\n",
       "          5.2020e-02, -1.4123e-02, -2.0408e-03,  9.3203e-03,  1.5221e-02,\n",
       "          5.1876e-02, -3.9700e-02, -5.7060e-03, -2.6038e-03,  6.3580e-03,\n",
       "         -2.7291e-02, -8.5843e-03, -2.7513e-02, -8.8620e-03,  2.4383e-04,\n",
       "          1.0068e-01,  6.5447e-02,  1.1463e-02, -1.7068e-02,  2.9303e-02,\n",
       "         -1.0257e-02,  3.7167e-02, -2.0620e-02,  6.4442e-03, -9.9187e-02,\n",
       "          4.2322e-02, -4.8182e-03, -3.0346e-02, -3.2955e-02, -3.4786e-02,\n",
       "         -3.5757e-02, -8.1767e-03,  2.2286e-02, -2.7997e-02, -7.1478e-04,\n",
       "          7.8046e-03, -2.5660e-02, -1.0418e-02, -1.1985e-02, -2.5260e-02,\n",
       "         -2.7969e-02, -3.8516e-02,  1.1418e-01, -1.8307e-02, -1.0973e-02,\n",
       "          9.7980e-03,  2.6654e-02, -3.0906e-02, -3.3043e-02,  1.2411e-02,\n",
       "          4.0714e-02,  2.2959e-03, -5.7870e-02,  1.5927e-02, -1.3885e-02,\n",
       "          9.2174e-03,  2.3395e-02, -2.5466e-03, -6.5759e-02, -7.9057e-03,\n",
       "          1.3101e-02, -3.0196e-02,  1.3841e-02, -6.5508e-03, -7.3960e-02,\n",
       "          3.0690e-02, -5.5186e-02,  4.4405e-02, -1.1878e-03, -2.7301e-03,\n",
       "         -2.7246e-02, -7.9239e-04,  6.3697e-02, -1.1991e-02, -3.3884e-02,\n",
       "          1.0575e-02,  1.9789e-02, -2.8523e-02,  2.5694e-02, -1.0080e-01,\n",
       "         -6.4948e-03,  1.9300e-02,  2.0170e-02, -4.2268e-03,  3.9764e-02,\n",
       "         -3.9720e-02,  5.3316e-02, -2.2441e-02,  7.8172e-03, -4.5522e-02,\n",
       "          3.4461e-03, -9.9075e-03,  1.3135e-02, -2.1538e-02,  4.2644e-02,\n",
       "         -2.6800e-03, -8.5643e-03,  4.2481e-02, -4.7788e-02, -3.4805e-03,\n",
       "          1.7614e-02, -3.2817e-02,  1.7591e-02, -2.9671e-02, -5.8553e-03,\n",
       "         -3.6791e-02, -7.4685e-03, -5.5805e-02, -1.3192e-02,  1.8202e-02,\n",
       "          2.4811e-02,  6.8183e-03, -3.0693e-02, -9.8621e-03,  2.2026e-02,\n",
       "         -8.4706e-03,  1.5254e-02,  1.1644e-02, -1.4381e-03,  1.8230e-02,\n",
       "         -1.7789e-02,  4.2445e-03, -5.9328e-02,  9.3283e-03, -3.2672e-02,\n",
       "          1.0204e-01,  1.9768e-02,  1.0964e-02, -9.9942e-03,  1.3524e-02,\n",
       "         -1.3421e-02, -1.1870e-03,  4.7052e-02, -9.7042e-02,  9.3137e-03,\n",
       "          8.9500e-03,  1.0774e-02,  8.3606e-02,  2.9623e-02,  1.0310e-01,\n",
       "         -1.0975e-02,  5.3574e-02, -1.4696e-02, -2.0240e-02, -1.9168e-02,\n",
       "          7.2391e-02, -1.6575e-03, -7.2371e-02, -4.4036e-02,  4.4082e-02,\n",
       "          1.7567e-02,  5.0200e-03, -2.9693e-02,  7.4723e-02, -4.0412e-02,\n",
       "          1.4060e-02, -4.9614e-02,  7.0181e-03, -4.9545e-02,  4.1126e-03,\n",
       "         -1.5247e-02, -1.2655e-02,  1.2737e-02, -3.2768e-03,  7.8539e-03,\n",
       "         -1.1654e-02, -3.5073e-03,  3.9867e-02, -3.5984e-03,  2.4887e-02,\n",
       "          1.1947e-02, -2.2594e-02, -1.2591e-02,  1.6425e-02,  8.3449e-03,\n",
       "         -1.2902e-02, -5.8289e-02, -2.8543e-02,  4.6036e-02, -3.0338e-02,\n",
       "          6.1654e-03,  1.7530e-02, -1.8561e-02, -6.7908e-03,  6.0556e-03,\n",
       "          2.1777e-02, -3.9666e-02, -2.6982e-03, -3.5760e-02,  1.1025e-03,\n",
       "          5.2260e-03,  1.0213e-02, -1.8933e-02, -2.1111e-02, -4.3610e-02,\n",
       "          3.9836e-02,  4.0513e-02, -5.9688e-03, -1.6513e-02, -4.7738e-02,\n",
       "          8.1397e-02, -1.3785e-02, -6.5834e-02,  1.0222e-01, -9.9315e-02,\n",
       "          3.5539e-02, -3.4159e-02,  6.5783e-03,  1.3559e-02,  1.6654e-02,\n",
       "         -1.7571e-02,  3.3041e-02, -5.5987e-04,  7.7079e-02,  1.4652e-02,\n",
       "         -2.8118e-02,  8.0673e-03, -3.6362e-02, -6.5124e-03,  5.8852e-02,\n",
       "          3.0636e-02, -4.5597e-02,  4.5532e-02,  1.5580e-02, -3.7854e-02,\n",
       "          3.0520e-02,  5.2865e-03,  3.9113e-02, -4.8027e-02,  3.4481e-02,\n",
       "         -2.1327e-03, -4.3797e-02, -5.8513e-02, -5.3495e-02,  5.9550e-03,\n",
       "          1.6909e-02,  8.3575e-03,  1.7611e-02, -3.3780e-04,  8.3315e-03,\n",
       "          2.2584e-02,  4.1335e-02, -6.9597e-02,  3.0540e-02, -9.1633e-02,\n",
       "          1.6627e-02,  1.6000e-02,  4.0497e-02, -3.8488e-02, -3.0428e-02,\n",
       "         -2.9797e-02, -5.3884e-04,  1.5816e-02, -3.3490e-02,  1.0078e-01,\n",
       "          1.1987e-02, -2.4973e-03,  1.1679e-02, -1.1208e-02, -5.5079e-04,\n",
       "          5.1852e-02, -2.0885e-02,  4.1902e-02,  1.2307e-02, -3.2866e-02,\n",
       "         -1.5866e-02,  4.4350e-02,  1.1173e-02,  4.9135e-02,  7.7859e-02,\n",
       "         -8.0359e-03,  9.8259e-03, -3.9951e-02,  3.1372e-02,  3.3666e-02,\n",
       "         -4.8512e-02, -1.6975e-03, -1.7866e-02,  3.4123e-02, -7.8872e-02,\n",
       "          1.6226e-02,  3.6809e-02,  1.0651e-01,  6.1249e-03, -4.0039e-02,\n",
       "         -1.9251e-02, -4.0490e-02, -3.7117e-02,  9.8318e-03,  5.3540e-02,\n",
       "          4.4614e-02, -3.7663e-02,  2.1105e-04,  1.4376e-02, -1.0833e-02,\n",
       "         -5.0133e-02, -1.0243e-01, -6.1907e-02, -5.9460e-02,  7.8544e-03,\n",
       "          2.2755e-02,  4.7144e-02, -8.6734e-03, -4.1631e-02, -2.2038e-02,\n",
       "          1.7260e-02, -7.8609e-02, -1.5686e-02,  2.4919e-02,  1.5853e-02,\n",
       "         -6.9563e-02, -1.3307e-02,  7.0851e-03,  3.7567e-02,  2.0932e-02,\n",
       "         -3.5008e-02, -7.5983e-02,  1.7958e-02, -5.4147e-02, -1.9581e-02,\n",
       "          1.5714e-02,  6.5203e-02,  8.0148e-02, -4.5967e-02, -2.0307e-02,\n",
       "          1.8379e-02, -7.4866e-03, -1.6249e-03,  6.3041e-03, -1.4236e-02,\n",
       "         -1.0788e-02,  2.7614e-02, -8.1731e-03, -4.4553e-02, -1.0530e-02,\n",
       "          1.9087e-02, -1.2958e-02,  3.1801e-02,  3.8866e-02, -3.1124e-02,\n",
       "         -1.6701e-02,  2.9904e-02, -5.5950e-03, -3.7753e-03, -3.1394e-02,\n",
       "          4.1315e-02, -1.5343e-02,  4.1217e-02, -2.1412e-02,  2.7605e-02,\n",
       "         -3.8371e-02,  1.3184e-02, -2.9085e-03,  1.9654e-03, -6.3788e-03,\n",
       "          1.1849e-02, -2.0978e-02, -5.3884e-02,  2.0506e-02, -1.3498e-02,\n",
       "          2.0262e-02, -2.1746e-02, -1.1879e-02, -7.7625e-02,  2.0937e-03,\n",
       "          6.3201e-02,  1.7469e-02, -7.7858e-03, -2.3737e-03,  3.6635e-02,\n",
       "          4.6044e-02, -9.1415e-03, -6.0501e-02,  9.5129e-03, -5.4561e-02,\n",
       "          8.9611e-02,  1.3883e-01,  2.2949e-02, -3.4627e-02, -1.5252e-02,\n",
       "          1.4927e-02, -7.2813e-02,  2.7549e-02,  3.2275e-02,  3.8709e-02,\n",
       "          2.6040e-02, -4.1264e-02,  3.9399e-02,  6.4339e-03, -5.1494e-02,\n",
       "         -1.9641e-02, -1.5259e-02, -2.3390e-02, -1.0278e-02,  2.3099e-02,\n",
       "         -5.9784e-33, -2.6005e-02, -5.7004e-02, -3.4476e-03, -7.2321e-02,\n",
       "         -1.3744e-02,  6.1441e-03, -1.1005e-02,  4.5438e-02, -3.2270e-02,\n",
       "         -2.8874e-02, -9.9697e-03,  1.4921e-02,  2.2435e-02,  7.4662e-03,\n",
       "         -9.2724e-03, -6.3310e-03, -2.5291e-03, -2.5509e-02,  4.4850e-03,\n",
       "         -6.6836e-02, -8.6988e-03,  2.7983e-02,  3.4283e-02,  1.4660e-02,\n",
       "         -1.7656e-02, -2.0396e-02, -5.0061e-03, -2.5807e-02, -5.5199e-02,\n",
       "          4.2905e-02, -4.1620e-02, -4.1155e-02, -1.0421e-02, -1.6425e-02,\n",
       "          2.5329e-02,  1.3550e-02, -3.0205e-02, -4.7398e-02,  1.0069e-03,\n",
       "          2.0344e-03, -8.6301e-02, -4.4392e-03, -2.8304e-03, -5.2532e-02,\n",
       "          2.5719e-04, -2.6272e-02,  2.4998e-02, -1.7822e-02, -1.6354e-02,\n",
       "          5.7475e-02, -5.7936e-02,  1.6557e-02, -9.5128e-03,  5.5306e-02,\n",
       "          6.5796e-02, -1.5616e-03,  7.9345e-03, -2.8869e-03, -6.2763e-03,\n",
       "         -6.6403e-03,  9.0889e-03,  3.2507e-02, -2.5347e-03, -4.0519e-03,\n",
       "          2.4574e-02,  3.5081e-02, -5.6168e-02,  8.1133e-03,  3.3233e-02,\n",
       "         -4.1477e-02,  4.5679e-02,  4.6645e-02,  3.2799e-02,  2.0128e-02,\n",
       "         -2.3764e-02, -6.3482e-02,  3.6916e-03,  2.9018e-02,  3.1700e-02,\n",
       "         -2.4016e-02,  1.8958e-02, -5.2400e-04, -5.3391e-02, -2.5788e-03,\n",
       "         -5.4757e-02, -7.3021e-02, -4.6921e-02, -8.6459e-02,  1.5756e-02,\n",
       "         -1.6275e-02, -1.9756e-02,  1.3305e-02,  1.2799e-02, -5.2233e-02,\n",
       "          4.7457e-03, -2.1343e-02, -1.6183e-02,  4.8519e-02, -1.3637e-02,\n",
       "         -2.5064e-02,  1.2529e-02, -1.8684e-02,  2.0649e-02, -7.8163e-03,\n",
       "          3.1622e-02, -3.0660e-03, -1.0440e-02, -3.9340e-02, -5.9176e-02,\n",
       "         -1.7654e-02,  2.1758e-02, -6.6238e-02,  2.6934e-02, -1.0373e-02,\n",
       "          4.2127e-03,  2.0652e-02,  1.5319e-02,  1.8220e-02,  6.4086e-02,\n",
       "          2.1409e-02, -4.9442e-02,  3.6212e-02, -5.4964e-02,  4.5302e-02,\n",
       "         -1.0897e-02, -1.3174e-02, -5.5072e-02,  7.0078e-02,  1.1276e-02,\n",
       "         -4.8131e-02,  4.5643e-06, -6.2324e-04,  2.1305e-07, -2.6060e-02,\n",
       "          7.5140e-02, -2.6260e-02,  1.3146e-02,  1.5953e-02, -1.5365e-02,\n",
       "         -6.2466e-02,  2.5697e-02,  5.9362e-02, -2.5600e-02,  2.1216e-02,\n",
       "         -2.9229e-02,  2.9460e-02,  1.5180e-02, -4.2473e-02, -4.3577e-03,\n",
       "         -1.2782e-02, -1.1880e-02, -2.0094e-02,  1.3873e-03, -8.9287e-03,\n",
       "          1.0459e-01,  3.4227e-02,  2.8689e-02,  1.5603e-03, -5.5679e-02,\n",
       "          1.4359e-02, -4.4711e-02,  2.0003e-03, -2.9805e-02,  7.4770e-03,\n",
       "          3.0288e-03,  2.8839e-02,  4.9741e-02, -3.9215e-02,  1.8939e-02,\n",
       "          3.0220e-02,  4.5663e-03,  3.1303e-02,  5.9107e-02,  1.8480e-02,\n",
       "         -7.5508e-03, -7.3337e-03, -7.7017e-02,  4.9755e-02, -1.2346e-02,\n",
       "          1.2251e-02, -5.9442e-02, -6.3908e-03, -2.4806e-02,  5.7017e-02,\n",
       "         -1.3984e-02,  5.6505e-03,  1.7318e-02,  5.7420e-03, -3.5224e-02,\n",
       "          3.7737e-02,  2.0808e-02,  4.7060e-02,  6.5803e-03, -5.3942e-02,\n",
       "         -4.1410e-02,  1.0645e-02,  5.3546e-03,  3.9682e-02, -9.5275e-03,\n",
       "         -2.6818e-02,  2.1862e-34, -1.2599e-03,  8.6353e-03,  4.1232e-02,\n",
       "          9.1922e-04,  2.6399e-02, -3.9402e-02,  6.4555e-02, -3.1777e-03,\n",
       "          2.1199e-02, -8.5429e-02, -2.0571e-02], device='cuda:0'),\n",
       " 'this is a second sentence for the model': tensor([ 3.9853e-02,  1.1305e-02, -1.5530e-02,  3.3976e-02, -3.2799e-02,\n",
       "          4.2354e-02,  1.6398e-02, -3.1444e-02, -2.6944e-02, -3.0731e-02,\n",
       "          4.7369e-02,  2.1103e-02,  3.3010e-02,  3.4032e-02,  3.8007e-02,\n",
       "         -6.5235e-02,  6.4036e-02, -6.4416e-03,  3.4543e-03, -9.0102e-03,\n",
       "         -1.7275e-02,  3.0512e-03,  4.5270e-03,  3.0739e-02, -7.7401e-03,\n",
       "         -2.2511e-02, -1.7440e-02,  1.8241e-02, -3.1460e-02, -2.4304e-02,\n",
       "          1.6757e-02,  4.2077e-02,  4.2986e-02, -5.7011e-02,  1.8659e-06,\n",
       "         -1.5055e-04, -3.5079e-02, -7.8792e-03, -6.3944e-02,  2.6660e-02,\n",
       "          2.7459e-02,  5.7436e-02, -2.7292e-03,  1.7998e-03, -1.7464e-02,\n",
       "          3.2718e-02,  1.7794e-02,  9.5034e-02, -5.1918e-02,  4.2457e-02,\n",
       "         -1.4360e-02, -1.8686e-02,  3.2093e-02, -2.7755e-02, -8.6776e-04,\n",
       "         -3.6427e-02,  2.8627e-02,  2.5594e-02,  5.2025e-03,  4.5981e-02,\n",
       "          1.4797e-02,  7.9453e-02,  1.4237e-02, -2.5163e-02,  8.5444e-02,\n",
       "         -2.9834e-03,  9.5523e-02, -4.8031e-02, -6.1396e-03, -1.3536e-02,\n",
       "          8.9872e-02,  1.1748e-02, -4.0469e-03,  6.4859e-02,  6.9229e-04,\n",
       "          6.1761e-03, -2.6548e-02,  1.7706e-02, -1.1893e-02,  2.8181e-03,\n",
       "          2.4235e-02,  1.0556e-02,  6.2031e-03, -1.9511e-02, -4.2652e-02,\n",
       "          4.8785e-02, -2.3748e-02,  1.5203e-02, -7.7336e-02,  1.7944e-02,\n",
       "         -6.4315e-02, -4.0665e-02, -4.3704e-03,  5.8987e-03, -1.7274e-02,\n",
       "         -1.1345e-02, -3.4770e-02,  1.4649e-03, -1.3459e-02, -7.6982e-02,\n",
       "          5.4125e-02, -5.1850e-02,  4.9801e-02,  1.1062e-02,  3.1806e-02,\n",
       "          3.0331e-02, -3.0433e-02,  1.9969e-02, -9.5139e-02,  4.2446e-02,\n",
       "         -3.2308e-02, -6.9475e-02, -7.0162e-02,  3.2449e-02, -2.7896e-02,\n",
       "         -3.8636e-02, -1.0051e-02, -5.4077e-04,  2.8931e-02, -1.5484e-02,\n",
       "         -3.0151e-02, -2.7219e-02, -2.4301e-02,  3.6257e-02,  4.5522e-03,\n",
       "          4.4990e-03, -1.4784e-02,  3.2180e-02,  4.5232e-02, -5.6787e-02,\n",
       "         -1.4046e-02, -1.5108e-02, -1.0389e-03, -9.0619e-03, -5.4341e-02,\n",
       "          3.3541e-02,  2.3445e-02,  5.5204e-03, -2.1864e-02, -2.7279e-02,\n",
       "          1.7869e-02, -6.3586e-02, -4.4193e-02, -5.5302e-03, -1.7853e-02,\n",
       "          2.9957e-02,  3.9190e-02, -4.8674e-02, -4.1793e-04,  6.2659e-04,\n",
       "         -2.6489e-02,  2.5906e-02, -4.3552e-02,  4.7569e-03, -4.0115e-03,\n",
       "         -4.5154e-03,  8.9170e-02,  4.0415e-02,  2.2299e-02, -2.4736e-02,\n",
       "          2.5039e-02,  4.3105e-02,  8.3646e-03, -2.1240e-02, -7.7749e-03,\n",
       "          8.8703e-03, -7.9582e-02,  8.9160e-03, -4.6286e-03, -2.8923e-02,\n",
       "         -2.3731e-02,  5.4706e-04, -2.2265e-02,  1.5990e-01,  3.0597e-02,\n",
       "          1.2955e-02,  2.0435e-02,  3.1622e-02, -4.2977e-02,  1.4323e-02,\n",
       "          9.7429e-04,  1.6631e-02, -3.4071e-02,  3.5967e-02, -1.1233e-01,\n",
       "          2.0006e-02, -4.9228e-02, -3.8982e-02, -3.2121e-02, -6.6063e-02,\n",
       "         -3.1331e-02,  1.6814e-02, -2.4086e-02, -9.0227e-03, -2.7560e-03,\n",
       "          4.1869e-02,  7.6388e-03,  6.6384e-02,  1.4605e-02, -1.7430e-02,\n",
       "         -9.3572e-03, -3.5865e-02,  5.2309e-02,  2.2023e-02, -3.6126e-02,\n",
       "          2.3450e-02, -3.0819e-02, -3.2380e-02, -8.0254e-03,  1.5455e-02,\n",
       "          9.6441e-02,  2.7848e-02,  8.6147e-04,  1.7256e-02, -1.8606e-02,\n",
       "         -4.1918e-02,  2.4476e-02, -2.4388e-02, -8.6696e-02, -6.1741e-03,\n",
       "         -1.5805e-02,  3.5293e-02, -2.8941e-02,  4.3219e-03, -6.5049e-02,\n",
       "          9.7916e-03, -6.5552e-02,  1.3934e-02, -2.1088e-02, -1.5394e-02,\n",
       "         -3.7195e-03,  3.6107e-02,  2.4913e-03,  2.6098e-02, -4.3429e-02,\n",
       "          1.8902e-02, -2.3169e-02, -1.3037e-02,  7.5416e-03, -4.3025e-03,\n",
       "          3.2323e-02,  1.6143e-02,  3.9453e-02,  4.6575e-03, -7.3162e-04,\n",
       "         -4.8476e-02,  4.0554e-02, -7.5506e-04,  4.1730e-02, -2.6559e-02,\n",
       "          2.4388e-02,  4.8815e-04,  3.3129e-03, -1.1612e-03, -3.4872e-02,\n",
       "         -1.2179e-02, -9.2883e-03,  1.9850e-02, -2.4988e-02,  9.3164e-03,\n",
       "          3.3207e-02, -6.3329e-03,  6.6795e-03,  7.1888e-03, -3.0185e-02,\n",
       "         -1.7846e-02,  1.6374e-03, -3.5521e-02, -9.5814e-03,  1.6352e-02,\n",
       "         -2.9561e-02, -4.3089e-03,  1.9897e-02, -2.3807e-02,  3.4024e-02,\n",
       "          1.2079e-02, -2.7157e-03, -2.9950e-03, -2.3881e-02,  2.6937e-02,\n",
       "          1.8528e-02, -2.5487e-02, -3.7470e-02, -4.0514e-03,  8.2205e-03,\n",
       "          2.2534e-02,  4.7312e-02, -3.2407e-02, -1.7173e-02,  5.8008e-02,\n",
       "         -5.8090e-03,  1.8212e-03,  2.3373e-02, -5.6652e-02,  7.4102e-03,\n",
       "         -2.4391e-02,  3.2246e-02,  3.1237e-02,  1.5179e-02,  1.3412e-01,\n",
       "         -2.4393e-02,  4.0968e-03, -1.2620e-02, -1.6514e-02, -2.6450e-02,\n",
       "          1.6528e-02, -4.5273e-02, -2.9881e-02, -2.0938e-02,  6.1509e-02,\n",
       "          3.6312e-02,  1.7396e-02,  2.1458e-02,  9.1353e-02, -7.3204e-03,\n",
       "         -2.3386e-02, -2.4082e-02, -6.5165e-03,  1.1754e-02,  5.2084e-02,\n",
       "         -9.9590e-03, -1.5071e-02, -6.5228e-03,  3.9643e-03,  2.8224e-03,\n",
       "         -1.6303e-02, -2.1513e-03,  3.2926e-02, -1.2071e-03,  6.2889e-03,\n",
       "          4.3672e-03,  3.9333e-02,  1.3804e-02,  2.5805e-02, -3.7047e-02,\n",
       "          1.4800e-02, -2.4140e-02, -4.1903e-02,  6.2090e-03,  1.5825e-02,\n",
       "         -1.1106e-02, -3.6344e-02,  4.8631e-03, -8.8057e-03, -5.0451e-02,\n",
       "          3.4278e-02, -4.2154e-02,  7.0655e-03, -8.6759e-02, -1.0548e-02,\n",
       "          4.1248e-02, -1.9380e-02, -5.3625e-02, -1.8268e-02, -6.1937e-02,\n",
       "         -2.1860e-02,  5.8745e-02, -1.5774e-02,  1.9555e-02, -8.4031e-02,\n",
       "          1.1441e-01, -2.4992e-03, -7.3775e-02,  8.2692e-02, -5.7786e-02,\n",
       "          1.1870e-02,  3.6838e-02,  7.2000e-02, -6.3100e-02, -7.4759e-03,\n",
       "          3.4238e-02,  1.9752e-02, -1.5140e-02,  6.1890e-02, -6.3183e-02,\n",
       "          3.2393e-02,  9.9806e-03, -1.5425e-02,  1.4819e-02,  3.9031e-02,\n",
       "          2.5635e-02,  2.1102e-03,  3.7029e-02,  4.0893e-02, -2.2786e-02,\n",
       "          5.3319e-03,  2.0831e-02, -4.1808e-02, -9.8035e-03,  6.5485e-02,\n",
       "          3.1954e-02, -4.1565e-02, -1.9602e-02,  6.4375e-03, -2.5579e-02,\n",
       "          7.0447e-03, -2.4169e-02,  3.7988e-02, -1.8700e-02,  1.6498e-02,\n",
       "          8.7205e-03,  6.0422e-02, -6.3196e-03, -3.4678e-02, -3.8459e-02,\n",
       "          1.3465e-02,  1.0788e-02,  1.7888e-02, -2.9886e-02,  6.7968e-02,\n",
       "          4.1838e-02,  8.2403e-03,  1.1116e-02, -3.1104e-04,  1.5779e-02,\n",
       "         -1.5699e-02, -1.7498e-02, -2.7905e-02,  5.9462e-03,  1.4504e-02,\n",
       "         -1.6118e-02, -7.9082e-03,  3.9147e-02, -4.6337e-03,  1.4434e-02,\n",
       "         -4.3789e-02,  2.3912e-02,  1.0225e-02,  1.5270e-02,  6.3828e-02,\n",
       "          6.1631e-03, -2.6617e-02, -5.4900e-02, -3.0768e-02, -3.5401e-02,\n",
       "         -1.0825e-02, -7.0304e-03, -2.4085e-02,  2.5945e-02, -3.4471e-02,\n",
       "         -1.1709e-03, -9.9391e-03,  1.1357e-01, -9.3461e-03,  2.5750e-02,\n",
       "          4.6495e-02, -4.1427e-03, -1.2249e-02, -7.0735e-03,  2.2822e-02,\n",
       "          9.9766e-03, -2.0785e-02, -9.8715e-03,  1.6122e-02, -2.8562e-02,\n",
       "         -4.3411e-02, -1.0124e-01, -5.1252e-02, -9.4552e-03,  3.2638e-03,\n",
       "          4.9235e-02,  4.6665e-02,  6.7352e-03, -1.7451e-02, -2.5992e-02,\n",
       "         -2.6486e-02, -8.8140e-03, -4.3058e-02,  1.2122e-02,  2.6457e-02,\n",
       "         -3.1122e-02,  4.5820e-03,  2.7846e-02,  2.4676e-02,  5.5400e-02,\n",
       "         -2.1554e-02, -5.3654e-02, -1.5820e-02, -5.0833e-02,  1.2347e-02,\n",
       "          3.8745e-02,  7.3890e-02,  5.5486e-02, -1.7145e-02, -3.9129e-02,\n",
       "          9.7843e-03, -4.0927e-02, -1.9026e-02, -5.2142e-02,  6.8539e-02,\n",
       "         -1.5030e-02,  2.0720e-02, -1.0242e-02, -4.5639e-02,  2.7364e-02,\n",
       "          1.5272e-02, -1.5777e-02,  2.4637e-02,  1.5942e-02, -3.9658e-02,\n",
       "         -2.8381e-03,  3.0131e-02,  1.3039e-02,  6.0629e-02, -3.2106e-02,\n",
       "         -1.4210e-02,  4.6195e-03,  8.5318e-03, -1.1917e-02,  1.2160e-02,\n",
       "         -8.6629e-02,  1.1121e-02, -3.1451e-02, -6.5299e-02, -4.4452e-03,\n",
       "          4.0792e-02, -2.6051e-02, -4.8159e-02,  4.7565e-02, -1.0418e-02,\n",
       "          9.0514e-03, -3.4119e-02,  5.4560e-02, -2.3783e-02, -5.3258e-02,\n",
       "          2.1054e-02,  6.1410e-03,  1.1378e-02, -8.9030e-02,  3.8761e-02,\n",
       "          5.1730e-02, -8.2405e-04, -9.7403e-02,  3.1316e-03, -4.5720e-02,\n",
       "         -2.1645e-02,  5.3725e-02, -7.5708e-02,  2.0489e-02,  2.0703e-02,\n",
       "          4.1119e-02, -6.2625e-02,  6.2363e-02,  2.0277e-02,  5.3635e-02,\n",
       "         -2.8824e-02, -2.0756e-02,  4.8505e-02, -6.1265e-03, -9.9842e-02,\n",
       "         -4.3463e-02, -5.6833e-03,  3.5134e-02,  3.5849e-02,  9.3612e-02,\n",
       "         -6.2474e-33, -5.3664e-02,  1.0866e-02, -4.3884e-03, -1.1630e-02,\n",
       "         -5.4441e-02, -1.6007e-02, -1.3713e-02,  2.8947e-02, -1.1638e-02,\n",
       "          3.3288e-03, -2.6542e-02,  2.2787e-02,  2.3279e-02,  6.0657e-03,\n",
       "          2.4356e-02,  2.7841e-03,  2.8626e-02, -1.4249e-02,  1.8259e-02,\n",
       "         -3.4038e-02,  5.2308e-03,  3.7962e-02,  6.1146e-02,  3.8321e-02,\n",
       "          1.8611e-02, -5.9574e-02, -3.9560e-02,  1.2600e-02, -8.0546e-02,\n",
       "          3.0029e-02, -1.5014e-02, -5.4546e-02, -5.8590e-03, -1.3316e-02,\n",
       "         -3.7077e-02,  8.4010e-03,  1.4955e-02, -2.2638e-02,  2.6839e-02,\n",
       "         -1.1520e-02, -7.0554e-02, -7.5731e-02, -5.6388e-03, -1.3329e-02,\n",
       "         -2.4963e-02, -4.2803e-02,  3.3230e-03, -7.6760e-02,  1.5658e-02,\n",
       "          1.1409e-02, -7.1467e-02, -7.4340e-03, -2.9106e-02,  5.4970e-02,\n",
       "          4.3238e-02,  1.6146e-02, -1.6422e-02, -2.7900e-02,  2.5108e-02,\n",
       "          1.9824e-02,  6.5068e-02,  5.1930e-02, -3.2640e-03,  1.7794e-02,\n",
       "          5.1171e-03,  6.4652e-04,  7.0565e-03,  1.1611e-02, -5.7526e-02,\n",
       "          3.6424e-02, -5.4919e-04,  8.5538e-02,  3.4907e-02,  3.3082e-02,\n",
       "         -3.4138e-02, -6.9273e-02, -4.9496e-02, -1.1869e-02, -2.8773e-03,\n",
       "          4.9830e-02,  2.5145e-02,  1.2393e-03, -1.6946e-02, -2.8228e-02,\n",
       "         -5.6037e-02, -8.6325e-02, -2.5273e-02,  1.0981e-02,  6.7939e-03,\n",
       "         -5.9140e-03,  1.7674e-02,  6.6238e-03, -1.2853e-02, -8.8420e-03,\n",
       "         -4.3084e-02, -5.0876e-04,  4.2477e-02,  1.0469e-02, -2.7855e-02,\n",
       "          1.1988e-02,  8.6652e-03, -7.9162e-03, -1.0821e-02,  5.0749e-02,\n",
       "          1.1994e-02,  5.7245e-02,  4.2382e-02,  1.4877e-03, -3.8429e-02,\n",
       "         -1.1310e-02, -7.9875e-03, -5.3664e-02,  3.1674e-02,  1.6109e-02,\n",
       "         -8.2438e-03, -1.6370e-02,  1.0861e-02,  7.9972e-02, -2.7136e-02,\n",
       "         -1.6811e-02, -2.8653e-02,  8.1450e-02, -3.2348e-02,  5.6956e-02,\n",
       "          9.5579e-03,  2.7384e-03, -5.3272e-02,  2.6178e-02,  3.2162e-02,\n",
       "         -5.9483e-02, -1.2844e-02, -9.7315e-03,  2.4954e-07, -1.4216e-02,\n",
       "          1.4514e-02,  1.1380e-02,  5.6232e-02,  8.4293e-03,  1.4116e-02,\n",
       "         -5.8524e-02,  2.3085e-02,  3.0009e-02,  4.3846e-02,  4.8183e-02,\n",
       "          7.2366e-03,  2.0919e-02, -4.0813e-02, -1.5853e-02,  1.5228e-02,\n",
       "         -6.1490e-02, -2.7012e-02, -2.0007e-02,  4.5877e-03, -1.6316e-02,\n",
       "          5.6832e-02,  6.1652e-02,  1.7046e-02, -1.9570e-02, -4.0925e-03,\n",
       "          9.7004e-03, -5.4825e-02,  2.9912e-03,  3.2864e-02,  5.0425e-02,\n",
       "         -6.3522e-03,  2.8457e-03,  2.3898e-02,  6.5618e-03, -1.0566e-02,\n",
       "          6.0513e-02,  7.2271e-02,  1.5968e-02,  4.7255e-02,  8.4878e-04,\n",
       "          1.7484e-03, -2.8498e-02, -3.5953e-02,  5.1570e-02, -2.7068e-02,\n",
       "          3.7393e-02, -6.1447e-02, -1.8251e-02,  1.3088e-02,  3.7689e-02,\n",
       "          2.3134e-03,  1.4958e-02, -8.6107e-03,  1.7932e-02, -4.0969e-02,\n",
       "          3.0196e-02,  1.2315e-02,  2.9049e-02, -3.1305e-04, -3.3843e-02,\n",
       "          1.3228e-02,  1.3911e-03,  4.7468e-03,  6.3460e-02, -5.4210e-02,\n",
       "         -2.7325e-02,  1.7667e-34,  2.4031e-02, -1.4227e-02,  8.9120e-03,\n",
       "          3.1289e-02,  5.7587e-03, -2.6737e-02,  4.3840e-02, -2.6024e-02,\n",
       "         -1.2408e-02, -4.9699e-02, -4.6748e-02], device='cuda:0'),\n",
       " 'The sky is blue': tensor([-2.2825e-03, -3.4933e-02,  2.9562e-03, -4.3063e-02, -3.9971e-02,\n",
       "         -3.5807e-02, -3.6068e-02, -9.4580e-03, -5.4959e-02,  3.0772e-02,\n",
       "         -3.2340e-03,  4.1537e-02,  3.1238e-02,  3.4090e-02,  5.6298e-02,\n",
       "         -1.3638e-01,  4.2279e-02, -3.8701e-03,  3.0775e-02,  2.4350e-03,\n",
       "          3.4368e-03,  2.0491e-02, -1.8735e-02, -4.2031e-02,  3.4437e-02,\n",
       "         -3.3553e-02, -4.1880e-03,  3.2970e-02,  3.9334e-02,  2.6029e-02,\n",
       "         -5.6698e-02, -3.7108e-02,  6.8113e-03, -3.7833e-02,  1.7468e-06,\n",
       "         -3.9490e-03,  4.3769e-03,  1.4412e-02,  3.7852e-02, -7.0734e-02,\n",
       "         -4.2909e-03,  3.3623e-03, -3.3486e-02,  4.7746e-02, -1.0369e-02,\n",
       "          7.8594e-03,  5.5545e-03,  8.0023e-02,  1.0587e-02,  4.8463e-03,\n",
       "         -1.4039e-04,  2.9871e-03, -4.1537e-02,  3.3504e-03,  2.6165e-02,\n",
       "         -2.3552e-02,  2.3621e-02,  3.7312e-02,  6.1450e-02,  4.3204e-02,\n",
       "         -1.1972e-02,  6.7264e-03,  6.6770e-03,  1.7248e-02,  1.5910e-02,\n",
       "          3.9992e-02,  1.7708e-02,  4.3123e-02, -2.1235e-02,  2.1698e-02,\n",
       "         -8.1313e-02, -1.1960e-02, -1.5603e-02,  1.4225e-02, -3.8444e-02,\n",
       "         -1.9401e-02,  9.5023e-03,  6.6408e-02,  4.4270e-02, -3.7558e-03,\n",
       "          4.2359e-02,  6.5853e-03, -1.0691e-02,  5.5916e-02,  1.4041e-02,\n",
       "          1.0285e-01,  4.1993e-04,  2.3820e-02,  1.1479e-02,  3.2298e-02,\n",
       "          2.0514e-02, -3.6793e-02, -4.1323e-02, -4.9383e-03, -1.2469e-02,\n",
       "          1.4996e-02, -1.5033e-02, -2.2357e-02, -4.8218e-02,  7.2232e-02,\n",
       "          8.3254e-02,  1.7673e-02,  2.3022e-02,  6.6403e-02,  1.7630e-02,\n",
       "         -1.0418e-02, -1.1241e-03, -8.8008e-02,  2.1003e-05,  6.3563e-03,\n",
       "          1.6257e-02, -1.5944e-03,  1.8828e-02, -6.9733e-02,  3.7898e-04,\n",
       "         -4.6258e-02,  1.7152e-02, -1.0642e-02,  3.1027e-02,  1.1260e-03,\n",
       "          2.7675e-02,  1.5531e-02,  1.3867e-03,  4.5955e-02, -3.7010e-03,\n",
       "         -3.0433e-02, -5.0106e-02,  3.1872e-02,  6.8573e-03, -7.9511e-02,\n",
       "         -6.6196e-03,  2.0857e-02, -8.1385e-03, -2.5583e-02, -9.7675e-03,\n",
       "         -6.5104e-02,  9.3662e-04,  8.3769e-03, -2.3396e-02, -2.4198e-02,\n",
       "          1.4035e-02, -1.6953e-02, -1.2315e-02,  1.5545e-02, -1.3231e-02,\n",
       "         -1.5094e-02,  1.3728e-02, -2.0972e-02, -9.7300e-03, -1.4862e-02,\n",
       "          1.7177e-02,  1.7143e-02, -1.0214e-01, -1.6632e-02, -2.4249e-02,\n",
       "         -7.5876e-03, -5.1679e-03,  7.0782e-03, -5.2447e-05, -1.9840e-02,\n",
       "          7.1352e-03, -1.6764e-02,  4.7146e-02, -1.1754e-02, -2.8574e-02,\n",
       "          1.2920e-02, -4.9653e-02, -4.0338e-03,  5.5704e-03,  1.5320e-02,\n",
       "          8.4139e-03, -2.6548e-02,  4.4777e-02,  6.5080e-02,  3.9609e-03,\n",
       "         -3.1207e-02, -7.4700e-02, -9.1172e-03, -6.8010e-03,  3.1626e-02,\n",
       "         -5.0209e-02, -2.2173e-02, -2.3936e-02,  3.4367e-02, -5.2217e-03,\n",
       "         -4.5040e-03,  4.5459e-02, -6.7912e-04, -3.9717e-02,  1.2685e-02,\n",
       "         -2.1683e-02,  1.4660e-02, -3.5248e-02,  1.5203e-02, -2.1409e-03,\n",
       "         -4.8604e-02,  3.0344e-02, -3.9621e-02, -1.0279e-02,  1.7211e-02,\n",
       "          6.8112e-03,  3.1580e-02,  3.8894e-02, -4.9930e-03, -4.2430e-02,\n",
       "         -6.4909e-03,  4.7240e-02, -2.5066e-02,  4.3697e-02, -4.5142e-02,\n",
       "          2.6420e-02,  8.1646e-03,  1.5767e-03,  1.5483e-02, -1.6024e-02,\n",
       "         -3.3539e-02, -1.1461e-02,  8.3144e-03, -2.2137e-02,  2.8950e-02,\n",
       "         -1.2181e-02,  2.0746e-02, -1.1959e-02,  2.8405e-02, -2.1360e-02,\n",
       "          3.8134e-02, -1.6502e-02,  6.3293e-03, -6.6321e-03, -3.2642e-03,\n",
       "         -2.6683e-02,  4.0777e-03,  4.0970e-02,  3.2725e-03, -2.7160e-02,\n",
       "          5.0842e-02,  4.3440e-03, -5.8465e-02, -4.3874e-02, -1.1498e-01,\n",
       "          4.1413e-02,  5.4210e-02, -2.3024e-02, -5.4029e-02, -1.2956e-02,\n",
       "          2.6615e-02, -8.0545e-02,  3.6652e-02, -6.8674e-03,  2.7225e-03,\n",
       "         -1.2266e-02,  2.9288e-02, -6.6803e-02, -1.3403e-02,  1.7891e-02,\n",
       "         -9.1660e-02,  7.9743e-02,  5.3128e-03, -8.9398e-02, -7.4644e-03,\n",
       "          6.9491e-03, -3.4920e-02,  6.0795e-03, -3.3058e-02,  2.4885e-02,\n",
       "         -1.7843e-02,  6.3762e-02,  5.6947e-02, -1.9847e-02, -1.6774e-02,\n",
       "          2.5326e-02,  3.4653e-02,  1.0847e-02, -2.5958e-02, -2.1221e-02,\n",
       "          6.2973e-03,  1.1216e-02, -1.4985e-03, -2.0956e-02,  1.4264e-03,\n",
       "         -1.5597e-03, -1.8684e-02, -1.1661e-02, -2.3481e-02,  1.3649e-02,\n",
       "          4.0571e-02,  3.1652e-02, -3.4197e-02, -2.6658e-02,  2.0671e-02,\n",
       "         -4.2109e-02,  1.2079e-02, -8.5386e-05,  9.1222e-02,  3.6086e-02,\n",
       "         -4.9038e-02, -5.8879e-02,  3.9603e-02,  2.7801e-02, -8.5881e-02,\n",
       "          2.5174e-02, -1.3287e-03,  1.2055e-02, -8.3580e-03,  2.4215e-02,\n",
       "          3.0564e-02,  7.6080e-04, -2.9743e-02,  1.5390e-02,  5.3103e-02,\n",
       "         -1.2024e-03,  3.5928e-05, -3.0384e-03,  5.8089e-02, -2.8156e-02,\n",
       "         -3.8615e-02, -5.4691e-02,  1.9795e-02,  9.4579e-03,  1.2146e-02,\n",
       "         -4.7964e-03, -2.7111e-02,  6.0842e-03,  3.8696e-04,  4.7004e-02,\n",
       "          1.7130e-02,  3.3382e-02,  4.4766e-02,  6.2630e-03, -7.6138e-02,\n",
       "          5.7530e-03,  1.0945e-01, -1.0176e-02, -1.3023e-02, -3.2689e-02,\n",
       "         -4.0509e-02, -6.6162e-04, -4.4832e-02, -7.1243e-02,  2.2733e-02,\n",
       "         -5.7531e-03, -1.3453e-03, -3.1444e-02, -3.1512e-02, -1.3944e-01,\n",
       "         -1.4577e-02, -3.2746e-02,  8.4679e-03,  4.0082e-02, -6.5705e-03,\n",
       "         -2.6659e-02, -1.2462e-02,  9.2320e-03,  1.0785e-02, -7.4542e-03,\n",
       "         -4.5248e-02,  7.8485e-03,  2.2816e-02,  5.5804e-02,  2.5005e-02,\n",
       "         -5.6232e-02, -1.1710e-02,  6.3076e-02,  8.1451e-02,  4.6921e-02,\n",
       "          5.0364e-02,  2.7519e-02,  3.9678e-02, -2.9139e-02,  4.5319e-03,\n",
       "          7.1570e-02,  1.1600e-02, -1.7895e-02,  3.9097e-02,  2.3615e-02,\n",
       "          6.3167e-02, -1.8048e-02, -5.1270e-02, -4.7114e-02,  1.1700e-03,\n",
       "          2.4956e-02,  2.4915e-02, -4.2496e-02,  1.4371e-02, -2.3863e-02,\n",
       "         -1.3921e-02,  6.2002e-03, -4.9871e-02,  8.5341e-03, -9.0498e-03,\n",
       "         -5.0842e-03,  2.3609e-02, -1.7137e-03, -1.0973e-02, -2.7391e-02,\n",
       "         -9.8974e-03,  1.7229e-02,  2.8927e-03,  2.6274e-02,  3.0823e-02,\n",
       "         -2.2344e-02,  6.9805e-02,  6.5384e-03,  6.8871e-02,  2.1311e-02,\n",
       "         -3.1630e-02,  7.9980e-02, -1.4534e-02, -5.6552e-02,  2.6547e-02,\n",
       "         -9.3353e-02, -4.3351e-02,  3.2137e-02, -7.1037e-03, -2.2831e-02,\n",
       "         -2.3149e-02, -1.4739e-02, -7.6403e-03,  9.6428e-03, -3.2605e-02,\n",
       "          1.1913e-02,  4.6951e-02,  5.5349e-03,  7.5545e-03, -1.4340e-02,\n",
       "          7.1334e-03,  3.2830e-02,  5.1056e-02,  1.2069e-02, -6.6378e-03,\n",
       "          1.2001e-03, -3.0820e-02, -1.0853e-02,  8.2872e-03, -1.1427e-02,\n",
       "         -1.4566e-02, -3.2552e-02,  5.9310e-02,  1.3576e-02, -1.0850e-02,\n",
       "          3.6222e-02,  1.2845e-02,  1.3626e-02, -1.4999e-02,  1.3186e-02,\n",
       "          1.8358e-02, -1.3111e-02,  2.0459e-02, -1.6627e-03,  9.8149e-03,\n",
       "          6.2373e-02, -1.4655e-02,  5.7126e-03, -1.0899e-02,  2.8023e-02,\n",
       "          1.1634e-02,  8.9251e-03, -5.6664e-02,  1.6891e-02, -2.3373e-02,\n",
       "          1.7695e-02,  8.7523e-03, -1.2794e-03,  2.5734e-02,  2.3579e-02,\n",
       "         -4.6057e-02, -8.6023e-02,  2.8676e-02,  3.4778e-02, -3.4053e-02,\n",
       "         -6.2038e-02,  2.3414e-02, -8.5060e-03,  2.2408e-02, -4.1468e-02,\n",
       "          2.0613e-02, -2.6713e-02, -2.4420e-03,  5.0983e-02, -1.5779e-02,\n",
       "         -2.0608e-02, -7.5893e-03, -4.8825e-03,  5.0468e-02, -4.9427e-03,\n",
       "         -5.2177e-02,  6.6282e-03, -3.6438e-02,  6.4898e-03,  3.2347e-02,\n",
       "         -7.1644e-03,  2.4268e-02,  4.4628e-03,  1.4003e-01, -7.5899e-03,\n",
       "         -2.5600e-02,  3.9250e-03, -3.1191e-02,  4.9241e-02, -7.3608e-02,\n",
       "         -3.0082e-02, -1.4374e-02,  3.5504e-03, -3.1300e-02,  2.9915e-03,\n",
       "         -5.3057e-03,  3.1259e-02,  5.7755e-03,  2.8416e-02, -3.7509e-02,\n",
       "          4.9972e-02, -3.9290e-03, -3.2338e-02, -4.2031e-02,  6.6439e-03,\n",
       "          3.7278e-02,  2.4235e-02,  2.4604e-02, -3.1010e-03, -2.8399e-02,\n",
       "         -1.9092e-02, -1.3866e-02,  5.2855e-03,  2.9730e-02, -1.9126e-02,\n",
       "          4.6171e-02, -9.5937e-03, -2.1837e-03,  1.0330e-02, -2.0748e-02,\n",
       "          1.9897e-02, -3.0480e-02,  3.4352e-02,  3.8011e-02, -1.2118e-02,\n",
       "          1.4271e-01, -7.1961e-02,  2.6760e-02,  1.0617e-02,  1.8807e-02,\n",
       "          3.5654e-03,  1.9628e-04,  9.1901e-02,  1.5609e-02,  2.4812e-02,\n",
       "         -1.3405e-03, -5.0612e-03, -3.5549e-05, -2.8834e-03, -6.7749e-02,\n",
       "         -1.8519e-02,  3.0409e-02, -8.0799e-02, -7.1526e-03,  1.6934e-02,\n",
       "         -6.7833e-33, -5.8653e-02,  1.3414e-03,  1.8321e-02, -1.3777e-01,\n",
       "         -3.2625e-02,  2.5221e-02, -5.0154e-02, -1.5594e-02, -6.3608e-02,\n",
       "          6.9453e-03, -5.2893e-02,  1.6209e-02,  1.7500e-02,  2.9913e-02,\n",
       "          4.6405e-02, -2.2065e-02, -9.8282e-03, -6.1530e-03, -1.2231e-02,\n",
       "         -2.3599e-02,  1.7852e-03,  1.6492e-02, -2.0501e-02,  3.5626e-02,\n",
       "          6.0900e-03,  5.4909e-02, -9.0867e-02, -1.6777e-03,  2.7810e-02,\n",
       "         -5.0843e-02, -1.7896e-02,  2.6952e-03,  6.8984e-03, -1.5884e-02,\n",
       "         -2.9024e-02,  8.6661e-02,  4.8325e-03, -2.6327e-02, -2.8751e-02,\n",
       "         -1.9790e-02, -1.3455e-01,  4.8511e-02, -2.5628e-02,  3.9622e-03,\n",
       "          1.3513e-03, -4.0998e-03, -1.3602e-02,  1.3832e-03,  2.7591e-02,\n",
       "         -1.1064e-02,  9.3728e-03, -8.7105e-03, -1.6068e-02, -5.9922e-02,\n",
       "         -4.8539e-02, -3.4479e-02,  2.0899e-02,  4.1199e-02,  3.7573e-02,\n",
       "          5.6441e-02,  1.0144e-01,  1.1501e-02,  2.4076e-03,  1.0630e-01,\n",
       "          7.1278e-02,  5.9861e-03, -4.7735e-03,  4.3774e-02, -6.7876e-02,\n",
       "          3.4724e-04,  3.7568e-02, -6.7324e-03, -6.3954e-03, -8.5206e-03,\n",
       "          1.4078e-03,  3.1230e-04, -1.9776e-02, -2.7693e-02,  6.1076e-02,\n",
       "          2.9033e-02, -3.1662e-02, -9.2380e-03, -7.1829e-03, -2.8735e-03,\n",
       "         -1.7170e-02, -3.8620e-02,  1.5233e-02,  4.9464e-02,  1.4487e-02,\n",
       "          6.9716e-03, -3.7107e-02,  2.7275e-02, -4.0072e-02,  5.0630e-03,\n",
       "         -9.0368e-02,  2.6213e-02, -9.2112e-03, -2.0397e-02,  3.2329e-02,\n",
       "          1.5870e-02, -3.3782e-02,  2.1346e-03, -2.9410e-02,  1.3844e-02,\n",
       "         -6.6348e-03,  2.4623e-02, -1.5389e-03, -7.7182e-03, -1.8630e-02,\n",
       "         -2.4298e-02,  1.1656e-02,  1.2559e-02,  1.6360e-02, -3.5071e-02,\n",
       "          8.9561e-03,  5.9214e-03,  1.2369e-02,  1.0203e-01, -1.7915e-02,\n",
       "         -3.7078e-02,  5.2096e-02, -3.6384e-02, -5.2343e-02,  3.7363e-02,\n",
       "         -6.3356e-03, -3.0898e-03,  1.0128e-02, -1.2334e-01, -3.2817e-02,\n",
       "          4.7301e-04, -2.5890e-02,  3.6734e-02,  2.3646e-07,  4.9387e-02,\n",
       "         -1.1462e-02,  3.0344e-02,  3.3989e-02, -2.7492e-02,  9.3552e-03,\n",
       "          1.4742e-03,  1.7381e-02,  1.9740e-02,  1.7266e-03, -2.5942e-02,\n",
       "         -1.5728e-02,  5.9055e-03, -4.1892e-02,  1.3337e-02,  1.1057e-01,\n",
       "          3.0714e-02, -3.9497e-02, -1.7624e-02, -2.5711e-02,  4.2791e-02,\n",
       "         -1.3531e-02,  1.8305e-02,  4.0069e-02,  2.6922e-03,  8.3644e-02,\n",
       "         -3.7694e-02, -1.8140e-02,  4.3988e-02, -4.2972e-02, -1.2004e-01,\n",
       "          3.9033e-02, -5.2765e-03, -1.0566e-02,  1.0090e-02,  3.1792e-02,\n",
       "          5.1824e-02,  1.8787e-02,  4.0979e-02,  3.6154e-02, -3.8467e-02,\n",
       "         -1.3861e-02,  6.3531e-04, -9.2401e-03,  4.2990e-02, -2.1141e-02,\n",
       "          8.4661e-03, -4.0343e-02, -2.0259e-02, -2.0130e-02, -1.5693e-02,\n",
       "          2.1164e-02,  1.1815e-02, -2.6185e-02, -1.4835e-02, -2.4472e-03,\n",
       "          3.6409e-02, -2.7575e-02, -1.5495e-02,  1.6636e-02,  2.7022e-03,\n",
       "          3.8045e-02,  1.7192e-02,  4.0091e-02, -3.1975e-02,  4.0068e-02,\n",
       "          1.7809e-02,  1.0925e-34, -7.7490e-04,  1.3340e-02, -2.8269e-02,\n",
       "         -4.6941e-02, -1.7544e-02,  2.1666e-02, -5.8457e-02, -4.1474e-02,\n",
       "          2.0868e-02,  1.5010e-02, -2.9637e-02], device='cuda:0')}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_and_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f3c1f030-b6bb-4bd4-9fe6-306d0fd919e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e9f00b0411146ab90fa8fbc73547258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1765 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 20s, sys: 4.67 s, total: 4min 25s\n",
      "Wall time: 53.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for item in tqdm(pages_and_chunks_over_min_token_len):\n",
    "    item[\"embedding\"] = embedding_model.encode(item[\"sentence_chunk\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff771519-be97-4c74-b7b2-7266c99518ca",
   "metadata": {},
   "source": [
    "# TODO\n",
    "## Creating a chromadb client for storing embeddings\n",
    "\n",
    "> **NOTE** maybe not\n",
    ">\n",
    "> [INFO] Time taken to get scores on 1765000 embeddings: 0.00286 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0cf22a6f-0c18-4e74-9260-e4344a6e1bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f45adc-b1fc-4346-949e-de2800e4b845",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ba664f6f-cd21-412c-ae83-8611e951ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-mpnet-base-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a52e39-3887-433e-a153-3a8d54a8e893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = collection.query(\n",
    "#     query_texts=[\"This is a query document about hawaii\"], # Chroma will embed this for you\n",
    "#     n_results=2 # how many results to return\n",
    "# )\n",
    "# print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e227f-b4c0-4bcc-81b0-b01891b9ebf7",
   "metadata": {},
   "source": [
    "## adding the embeddings to the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b0021cc9-4e03-4dd1-8e22-813b4a5d31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 661 μs, sys: 19 μs, total: 680 μs\n",
      "Wall time: 690 μs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['The CNN applies an overall stride of 32 to theinput image (i.e., if you add up all the strides greater than 1), meaning the lastlayer outputs feature maps that are 32 times smaller than the input image. This is clearly too coarse, so they added a single upsampling layer thatmultiplies the resolution by 32. There are several solutions available for upsampling (increasing the size of an',\n",
       " 'tf.keras.layers. TextVectorization, Text Preprocessing-TextPreprocessing, Creating the Training Dataset, Building and Training theChar-RNN Model, Sentiment Analysis, Sentiment Analysis-AnEncoder–Decoder Network for Neural Machine Translationtf.keras.layers. TimeDistributed, Forecasting Using a Sequence-to-Sequence Modeltf.keras.losses. Huber, Custom Loss Functionstf.keras.losses.kullback_leibler_divergence(), Sparse Autoencoderstf.keras.losses. Loss, Saving and Loading Models That Contain CustomComponentstf.keras.losses.sparse_categorical_crossentropy(), Compiling the model,CNN Architectures, Building and Training the Char-RNN Model, AnEncoder–Decoder Network for Neural Machine Translation, HuggingFace’s Transformers Librarytf.keras.metrics. MeanIoU, Classification and Localizationtf.keras.metrics. Metric, Custom Metricstf.keras.metrics. Precision, Custom Metricstf.keras. Model, Building Complex Models Using the Functional APItf.keras.models.clone_model(), Using the Subclassing API to BuildDynamic Models, Transfer Learning with Kerastf.keras.models.load_model(), Saving and Restoring a Model, Savingand Loading Models That Contain Custom Components-Saving andLoading Models That Contain Custom Components, Custom Models,Training at Scale Using the Distribution Strategies APItf.keras.optimizers. Adam, Building a Regression MLP Using theSequential API, AdamW',\n",
       " 'All the multilayer neural networks we’ve looked at so far had layers composed of a longline of neurons, and we had to flatten input images to 1D before feeding them to the neuralnetwork. In a CNN each layer is represented in 2D, which makes it easier to matchneurons with their corresponding inputs. A neuron located in row i, column j of a given layer is connected to theoutputs of the neurons in the previous layer located in rows i to i + f – 1,columns j to j + f – 1, where f and f are the height and width of thereceptive field (see Figure 14-3). In order for a layer to have the same heightand width as the previous layer, it is common to add zeros around the inputs,as shown in the diagram. This is called zero padding. It is also possible to connect a large input layer to a much smaller layer byspacing out the receptive fields, as shown in Figure 14-4. This dramaticallyreduces the model’s computational complexity. The horizontal or verticalstep size from one receptive field to the next is called the stride. In thediagram, a 5 × 7 input layer (plus zero padding) is connected to a 3 × 4 layer,using 3 × 3 receptive fields and a stride of 2 (in this example the stride is thesame in both directions, but it does not have to be so). A neuron located inrow i, column j in the upper layer is connected to the outputs of the neuronsin the previous layer located in rows i × s to i × s + f – 1, columns j × s toj × s + f – 1, where s and s are the vertical and horizontal strides.hwhwhhhwwwhw']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "text_chunks = [item[\"sentence_chunk\"] for item in pages_and_chunks_over_min_token_len]\n",
    "random.sample(text_chunks, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f58305b3-6a9d-4679-975b-44283b91acfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_chunks' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Embed all the text in batches\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m text_chunks_embeddings \u001b[38;5;241m=\u001b[39m embedding_model\u001b[38;5;241m.\u001b[39mencode(\u001b[43mtext_chunks\u001b[49m,\n\u001b[1;32m      4\u001b[0m                                                batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m      5\u001b[0m                                                convert_to_tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      6\u001b[0m text_chunks_embeddings\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_chunks' is not defined"
     ]
    }
   ],
   "source": [
    "# Embed all the text in batches\n",
    "\n",
    "text_chunks_embeddings = embedding_model.encode(text_chunks,\n",
    "                                               batch_size=32,\n",
    "                                               convert_to_tensor=True)\n",
    "text_chunks_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9e7a7b-d735-451a-ada4-0628818f5591",
   "metadata": {},
   "source": [
    "### Saving embeddings into a file (Temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d26e6a02-5774-44c9-8974-8f728738aa70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pages_and_chunks_over_min_token_len' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m text_chunks_and_embeddings_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mpages_and_chunks_over_min_token_len\u001b[49m)\n\u001b[1;32m      2\u001b[0m embeddings_df_save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membedding/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpdf_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m text_chunks_and_embeddings_df\u001b[38;5;241m.\u001b[39mto_csv(embeddings_df_save_path, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pages_and_chunks_over_min_token_len' is not defined"
     ]
    }
   ],
   "source": [
    "text_chunks_and_embeddings_df = pd.DataFrame(pages_and_chunks_over_min_token_len)\n",
    "embeddings_df_save_path = f\"embedding/{pdf_file_name}.csv\"\n",
    "text_chunks_and_embeddings_df.to_csv(embeddings_df_save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "54939d30-c850-421b-a354-9e8d941ba877",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_number</th>\n",
       "      <th>sentence_chunk</th>\n",
       "      <th>chunk_char_count</th>\n",
       "      <th>chunk_word_count</th>\n",
       "      <th>chunk_token_count</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Hands-On Machine Learning withScikit-Learn, Ke...</td>\n",
       "      <td>150</td>\n",
       "      <td>14</td>\n",
       "      <td>37.50</td>\n",
       "      <td>[-2.78972145e-02 -1.74421235e-03 -4.81583700e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>Hands-On Machine Learning with Scikit-Learn, K...</td>\n",
       "      <td>873</td>\n",
       "      <td>97</td>\n",
       "      <td>218.25</td>\n",
       "      <td>[ 2.48818621e-02  6.14474006e-02 -5.22879586e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Revision History for the Third Edition2022-10-...</td>\n",
       "      <td>1152</td>\n",
       "      <td>159</td>\n",
       "      <td>288.00</td>\n",
       "      <td>[ 9.69696417e-03 -2.23619733e-02 -4.10474986e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>The Machine Learning TsunamiIn 2006, Geoffrey ...</td>\n",
       "      <td>1173</td>\n",
       "      <td>171</td>\n",
       "      <td>293.25</td>\n",
       "      <td>[-3.19831981e-03  1.02457978e-01 -5.40223382e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>Machine Learning in Your ProjectsSo, naturally...</td>\n",
       "      <td>867</td>\n",
       "      <td>131</td>\n",
       "      <td>216.75</td>\n",
       "      <td>[ 4.60035866e-03  9.44859162e-02 -7.24032298e-...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page_number                                     sentence_chunk  \\\n",
       "0            2  Hands-On Machine Learning withScikit-Learn, Ke...   \n",
       "1            3  Hands-On Machine Learning with Scikit-Learn, K...   \n",
       "2            5  Revision History for the Third Edition2022-10-...   \n",
       "3            7  The Machine Learning TsunamiIn 2006, Geoffrey ...   \n",
       "4            8  Machine Learning in Your ProjectsSo, naturally...   \n",
       "\n",
       "   chunk_char_count  chunk_word_count  chunk_token_count  \\\n",
       "0               150                14              37.50   \n",
       "1               873                97             218.25   \n",
       "2              1152               159             288.00   \n",
       "3              1173               171             293.25   \n",
       "4               867               131             216.75   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-2.78972145e-02 -1.74421235e-03 -4.81583700e-...  \n",
       "1  [ 2.48818621e-02  6.14474006e-02 -5.22879586e-...  \n",
       "2  [ 9.69696417e-03 -2.23619733e-02 -4.10474986e-...  \n",
       "3  [-3.19831981e-03  1.02457978e-01 -5.40223382e-...  \n",
       "4  [ 4.60035866e-03  9.44859162e-02 -7.24032298e-...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading the csv \n",
    "\n",
    "text_chunks_and_embedding_df_load = pd.read_csv(embeddings_df_save_path)\n",
    "text_chunks_and_embedding_df_load.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5ab7f457-5ef5-4fb0-bb0c-477467a8622e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Similarity FeaturesAnother technique to tackle nonlinear problems is to add features computedusing a similarity function, which measures how much each instanceresembles a particular landmark, as we did in Chapter 2 when we added thegeographic similarity features. For example, let’s take the 1D dataset fromearlier and add two landmarks to it at x = –2 and x = 1 (see the left plot inFigure 5-8). Next, we’ll define the similarity function to be the Gaussian RBFwith γ = 0.3. This is a bell-shaped function varying from 0 (very far awayfrom the landmark) to 1 (at the landmark). Now we are ready to compute the new features. For example, let’s look at theinstance x = –1: it is located at a distance of 1 from the first landmark and 2from the second landmark. Therefore, its new features are x = exp(–0.3 × 1 )≈ 0.74 and x = exp(–0.3 × 2 ) ≈ 0.30. The plot on the right in Figure 5-8shows the transformed dataset (dropping the original features). As you cansee, it is now linearly separable. Figure 5-8. Similarity features using the Gaussian RBFYou may wonder how to select the landmarks. The simplest approach is tocreate a landmark at the location of each and every instance in the dataset.'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df_load[\"sentence_chunk\"].iloc[357]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4e945-7032-4e92-acdc-443cd002cc64",
   "metadata": {},
   "source": [
    "# Rag - Search and Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1133ffac-cc97-497f-970a-9672c723d6a1",
   "metadata": {},
   "source": [
    "### Similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fb65de4-2d15-46d3-bb2b-c2ba49837354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[INFO]\u001b[0m This is an info\n",
      "\u001b[31m[ERROR]\u001b[0m This is an error\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style\n",
    "\n",
    "def print_message(message_type, message):\n",
    "    if message_type == \"INFO\":\n",
    "        print(f\"{Fore.YELLOW}[INFO]{Style.RESET_ALL} {message}\")\n",
    "    elif message_type == \"ERROR\":\n",
    "        print(f\"{Fore.RED}[ERROR]{Style.RESET_ALL} {message}\")\n",
    "    elif message_type == \"SUCCESS\":\n",
    "        print(f\"{Fore.GREEN}[SUCESS]{Style.RESET_ALL} {message}\")\n",
    "    else:\n",
    "        print(f\"{message}\")\n",
    "\n",
    "print_message(\"INFO\", \"This is an info\")\n",
    "print_message(\"ERROR\", \"This is an error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c109a23-1d71-428b-a1c6-2511acfb5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac7b5cf3-c3e6-447a-97c8-32b388310c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1765, 768])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Import texts and embedding df\n",
    "text_chunks_and_embedding_df = pd.read_csv(\"Hands-On Machine Learning With - Aurelien Geron.pdf.csv\")\n",
    "\n",
    "# Convert embedding column back to np.array (it got converted to string when it got saved to CSV)\n",
    "text_chunks_and_embedding_df[\"embedding\"] = text_chunks_and_embedding_df[\"embedding\"].apply(lambda x: np.fromstring(x.strip(\"[]\"), sep=\" \"))\n",
    "\n",
    "# Convert texts and embedding df to list of dicts\n",
    "pages_and_chunks = text_chunks_and_embedding_df.to_dict(orient=\"records\")\n",
    "\n",
    "# Convert embeddings to torch tensor and send to device (note: NumPy arrays are float64, torch tensors are float32 by default)\n",
    "embeddings = torch.tensor(np.array(text_chunks_and_embedding_df[\"embedding\"].tolist()), dtype=torch.float32).to(device)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ec8893-78cc-4a19-804e-730fdbfb9c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0279, -0.0017, -0.0482,  ...,  0.0007, -0.0182, -0.0057],\n",
       "        [ 0.0249,  0.0614, -0.0523,  ...,  0.0169, -0.0166, -0.0051],\n",
       "        [ 0.0097, -0.0224, -0.0410,  ..., -0.0104, -0.0108, -0.0204],\n",
       "        ...,\n",
       "        [ 0.0017,  0.0756, -0.0428,  ...,  0.0299,  0.0373, -0.0241],\n",
       "        [-0.0071,  0.0351, -0.0043,  ...,  0.0399,  0.0262, -0.0321],\n",
       "        [ 0.0198,  0.0750, -0.0211,  ...,  0.0131, -0.0042, -0.0147]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6f42b87-e5b9-4f83-bf46-eaca565e74db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/smitsis/rag_from_scratch/.venv/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# creeating the model, this is just used if you havent already run the model above\n",
    "\n",
    "from sentence_transformers import util, SentenceTransformer\n",
    "\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name_or_path=\"all-mpnet-base-v2\", \n",
    "                                      device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f368d299-0b1f-4beb-a85b-0d6159c5a89d",
   "metadata": {},
   "source": [
    "#### TODO: semantic search pipeline\n",
    "\n",
    "\n",
    "1. Define a query string.\n",
    "2. Turn the query string into an embedding\n",
    "3. Perform a dot product or cosine similarity function between the text embedding and the query embedding\n",
    "4. Sort the results from k in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "166a5ed3-c7df-4fe5-8393-7db8586e8ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Ridge regression\n",
      "\u001b[33m[INFO]\u001b[0m Time taken to get scores on 1765 embeddings: 0.00078 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([0.6800, 0.6272, 0.6144, 0.6123, 0.6080, 0.5475, 0.5370, 0.5321, 0.5214,\n",
       "        0.5082, 0.5047, 0.4858, 0.4855, 0.4808, 0.4768, 0.4709, 0.4702, 0.4683,\n",
       "        0.4650, 0.4572, 0.4565, 0.4548, 0.4508, 0.4493, 0.4492, 0.4465, 0.4458,\n",
       "        0.4445, 0.4379, 0.4372, 0.4280, 0.4275, 0.4275, 0.4272, 0.4259, 0.4257,\n",
       "        0.4249, 0.4243, 0.4229, 0.4199, 0.4197, 0.4187, 0.4175, 0.4170, 0.4167,\n",
       "        0.4134, 0.4134, 0.4126, 0.4111, 0.4110, 0.4093, 0.4087, 0.4055, 0.4054,\n",
       "        0.4037, 0.4026, 0.4021, 0.4020, 0.4014, 0.4010, 0.3998, 0.3974, 0.3938,\n",
       "        0.3927, 0.3901, 0.3892, 0.3884, 0.3853, 0.3839, 0.3807, 0.3799, 0.3799,\n",
       "        0.3795, 0.3793, 0.3774, 0.3771, 0.3764, 0.3719, 0.3700, 0.3679, 0.3677,\n",
       "        0.3655, 0.3650, 0.3641, 0.3638, 0.3618, 0.3612, 0.3611, 0.3610, 0.3605,\n",
       "        0.3603, 0.3596, 0.3592, 0.3590, 0.3576, 0.3576, 0.3576, 0.3573, 0.3569,\n",
       "        0.3562], device='cuda:0'),\n",
       "indices=tensor([ 309,  312,  341,  311,  310,  315, 1694,  270,  337,  313,  339, 1693,\n",
       "         380,  364,  366,   62, 1729,  308,  272,  284,  338,  377,  271,  353,\n",
       "         636,  269,  297, 1721,  373, 1722,  381,  317,  340, 1727,  344,   27,\n",
       "          91, 1762,  379, 1638, 1691, 1654,  368,   77,  365, 1730,  495,  274,\n",
       "         214,  314,  405,  278,  357,    1,  383, 1738,  287,  316, 1753,  384,\n",
       "           2, 1734,  356,  371,   26,  593,  461,  376,  382,  467,   11,  355,\n",
       "         496,  280, 1743,  299,   75,  503, 1640,  500,  441,  275,   15, 1732,\n",
       "         326,   93,  352,  335,  277,  276,  348,  360,  414,  286,   90,  285,\n",
       "         265,  697,  302,  420], device='cuda:0'))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Ridge regression\"\n",
    "print(f\"Query: {query}\")\n",
    "\n",
    "# embed query\n",
    "query_embedding = embedding_model.encode(query, convert_to_tensor=True)\n",
    "\n",
    "\n",
    "# Get similarity scores with dot product (use cosine similarity if outputs are not normalized)\n",
    "\n",
    "from time import perf_counter as timer\n",
    "\n",
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=embeddings)[0]\n",
    "end_time = timer()\n",
    "\n",
    "print_message(\"INFO\", f\"Time taken to get scores on {len(embeddings)} embeddings: {end_time - start_time:.5f} seconds.\")\n",
    "\n",
    "# 4 get top-k results\n",
    "\n",
    "top_results_dot_product = torch.topk(dot_scores, k=100)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9875324b-12fa-4855-a6a0-4dac4ed793a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ridge RegressionRidge regression (also called Tikhonov regularization) is a regularizedversion of linear regression: a regularization term equal to αm∑i=1nθi2 isadded to the MSE. This forces the learning algorithm to not only fit the databut also keep the model weights as small as possible. Note that theregularization term should only be added to the cost function during training. Once the model is trained, you want to use the unregularized MSE (or theRMSE) to evaluate the model’s performance. The hyperparameter α controls how much you want to regularize the model. If α = 0, then ridge regression is just linear regression. If α is very large, thenall weights end up very close to zero and the result is a flat line going throughthe data’s mean. Equation 4-8 presents the ridge regression cost function.\\u2060Equation 4-8. Ridge regression cost functionJ(θ)=MSE(θ)+αm∑i=1nθi2Note that the bias term θ is not regularized (the sum starts at i = 1, not 0). Ifwe define w as the vector of feature weights (θ to θ ), then the regularizationterm is equal to α(∥ w ∥) / m, where ∥ w ∥ represents the ℓ norm ofthe weight vector.\\u2060 For batch gradient descent, just add 2αw / m to the partof the MSE gradient vector that corresponds to the feature weights, withoutadding anything to the gradient of the bias term (see Equation 4-6). WARNINGIt is important to scale the data (e.g., using a StandardScaler) before performing ridgeregression, as it is sensitive to the scale of the input features. This is true of mostregularized models.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks_and_embedding_df[\"sentence_chunk\"].iloc[309]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed20aac0-6e8f-4683-8822-b8720e527fad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "just dot prod 0.6800\n",
      "cosine similarity 0.6800\n"
     ]
    }
   ],
   "source": [
    "dot = torch.dot(embeddings[309], query_embedding)\n",
    "print(f\"just dot prod {dot:.4f}\")\n",
    "dot = dot / (torch.sqrt(torch.sum(embeddings[309] ** 2)) *  torch.sqrt(torch.sum(query_embedding ** 2))) \n",
    "print(f\"cosine similarity {dot:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16ff067c-6ccb-4cdb-a63a-9592f2dabb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.sqrt(torch.sum(embeddings[309] ** 2)) *  torch.sqrt(torch.sum(query_embedding ** 2))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9463df84-6bdf-4124-8dec-27fdc77c7e8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape torch.Size([1765000, 768])\n"
     ]
    }
   ],
   "source": [
    "larger_embeddings = torch.rand(1000*embeddings.shape[0], 768).to(device)\n",
    "print(f'Embeddings shape {larger_embeddings.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec32072e-65b7-4333-b546-6e4ff9d9759c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m[INFO]\u001b[0m Time taken to get scores on 1765000 embeddings: 0.00286 seconds.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([1.5886, 1.5866, 1.5200, 1.5178, 1.5173, 1.5087, 1.4967, 1.4873, 1.4778,\n",
       "        1.4660, 1.4611, 1.4571, 1.4494, 1.4467, 1.4458, 1.4402, 1.4304, 1.4287,\n",
       "        1.4246, 1.4229, 1.4207, 1.4195, 1.4176, 1.4146, 1.4123, 1.4107, 1.4094,\n",
       "        1.4039, 1.4033, 1.4002, 1.3973, 1.3921, 1.3899, 1.3880, 1.3832, 1.3825,\n",
       "        1.3814, 1.3801, 1.3792, 1.3791, 1.3785, 1.3779, 1.3764, 1.3748, 1.3731,\n",
       "        1.3728, 1.3727, 1.3723, 1.3668, 1.3668, 1.3634, 1.3628, 1.3623, 1.3604,\n",
       "        1.3603, 1.3602, 1.3599, 1.3587, 1.3586, 1.3580, 1.3570, 1.3570, 1.3568,\n",
       "        1.3568, 1.3565, 1.3562, 1.3554, 1.3546, 1.3544, 1.3494, 1.3489, 1.3487,\n",
       "        1.3463, 1.3428, 1.3414, 1.3387, 1.3382, 1.3376, 1.3355, 1.3342, 1.3330,\n",
       "        1.3330, 1.3329, 1.3314, 1.3294, 1.3279, 1.3264, 1.3262, 1.3236, 1.3231,\n",
       "        1.3214, 1.3192, 1.3174, 1.3167, 1.3154, 1.3141, 1.3140, 1.3137, 1.3130,\n",
       "        1.3127], device='cuda:0'),\n",
       "indices=tensor([ 721033,  317068,  700443, 1130865, 1186948, 1360673, 1727258, 1124865,\n",
       "         534869, 1497477, 1029902, 1373345, 1439925,  444199, 1299250,  546276,\n",
       "         657906,  123587, 1562289,  170280,  405047,   22487,  663014,   90366,\n",
       "        1031829,  516493, 1285134, 1245268, 1758254,  114921, 1673239, 1369935,\n",
       "         486510,  461835,  418618,  933310,  941736, 1270384, 1472048, 1284426,\n",
       "        1146418, 1161902, 1682953, 1116955,  134418, 1034216, 1198416, 1024963,\n",
       "        1120876, 1616815,  248175, 1043158, 1124131, 1236892, 1634856,  231763,\n",
       "         152524,  518393,  430397, 1531492,  400312,  885911,   74235, 1229747,\n",
       "        1594692,  725692, 1563634, 1169925,  441604,  303821,  592916, 1303342,\n",
       "          89539,  715391,  584518,  434111, 1738048,  193581,  873516, 1391704,\n",
       "        1459553,   45523,  595891, 1299913,  878081, 1487730,  993679, 1330676,\n",
       "        1167358, 1337677, 1569999,  617017, 1650760,  544625, 1497255, 1582686,\n",
       "         924374, 1606489, 1374096,  393325], device='cuda:0'))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time = timer()\n",
    "dot_scores = util.dot_score(a=query_embedding, b=larger_embeddings)[0]\n",
    "end_time = timer()\n",
    "# print(dot_scores.shape)\n",
    "\n",
    "print_message(\"INFO\", f\"Time taken to get scores on {len(larger_embeddings)} embeddings: {end_time - start_time:.5f} seconds.\")\n",
    "\n",
    "\n",
    "top_results_dot_product = torch.topk(dot_scores, k=100)\n",
    "top_results_dot_product"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c99967-d9e0-442d-a518-66a0ce2fb802",
   "metadata": {},
   "source": [
    "### Implementing a Re-Ranker\n",
    "\n",
    "- Re-rank the top k=100 results\n",
    "- Select the top=5 results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_scratch",
   "language": "python",
   "name": "rag_scratch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
